{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /mnt/e/py_data/project_3_git/code\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ì‘ì—… ê²½ë¡œ ì„¤ì •\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"project_3_git/code/3_lm_t5.ipynb\")\n",
    "notebook_dir = os.path.dirname(notebook_path)\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì¶œë ¥\n",
    "print(\"Current working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í† ì´ ë°ì´í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"input_text\": \"ì›ƒìŒ,ê½ƒë°­\", \"target_text\": \"ê½ƒë°­ì—ì„œ ì›ƒê³  ê³„ì‹œë‹ˆ ì •ë§ ê¸°ì˜ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ë°”ë‹¤\", \"target_text\": \"ë°”ë‹¤ì™€ í•¨ê»˜ í–‰ë³µí•œ ìˆœê°„ì„ ë³´ë‚´ê³  ê³„ì‹œë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ì‚°ì±…ë¡œ\", \"target_text\": \"ì‚°ì±…ë¡œì—ì„œ ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ê³  ê³„ì‹œë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ì¹´í˜\", \"target_text\": \"ì¹´í˜ì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ ì •ë§ í–‰ë³µí•´ ë³´ì´ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,ë„ì„œê´€\", \"target_text\": \"ë„ì„œê´€ì—ì„œ ê¸°ìœ í‘œì •ì„ ë³´ë‹ˆ ì§€ì‹ì˜ í˜ì´ ëŠê»´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í™œë ¥,ìì „ê±°\", \"target_text\": \"ìì „ê±°ë¥¼ íƒ€ê³  í™œê¸°ì°¬ ëª¨ìŠµì´ ë©‹ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ì •ì›\", \"target_text\": \"ì •ì›ì—ì„œ í–‰ë³µí•œ ì‹œê°„ ë³´ë‚´ì‹œëŠ” ëª¨ìŠµì´ ì•„ë¦„ë‹µìŠµë‹ˆë‹¤!\"},\n",
    "    {\"input_text\": \"ì›ƒìŒ,í”¼í¬ë‹‰\", \"target_text\": \"í”¼í¬ë‹‰ì—ì„œ ì›ƒê³  ê³„ì‹œë‹ˆ ì¦ê±°ìš´ ì‹œê°„ì´êµ°ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,ê³µì›\", \"target_text\": \"ê³µì›ì—ì„œ ê¸°ë»í•˜ëŠ” ëª¨ìŠµì´ ì°¸ ë³´ê¸° ì¢‹ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ì‚°\", \"target_text\": \"ì‚°ì—ì„œ í–‰ë³µí•œ í‘œì •ì„ ì§€ìœ¼ì‹œë‹ˆ ë©‹ì§„ ìì—°ì„ ë§Œë½í•˜ê³  ê³„ì‹œë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,í•´ë³€\", \"target_text\": \"í•´ë³€ì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ ì •ë§ í‰í™”ë¡œì›Œ ë³´ì´ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ìˆ˜ì˜ì¥\", \"target_text\": \"ìˆ˜ì˜ì¥ì—ì„œ ì¦ê±°ì›Œí•˜ëŠ” ëª¨ìŠµì´ ì•„ì£¼ ê¸°ì˜ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,í™”ì›\", \"target_text\": \"í™”ì›ì—ì„œ ê¸°ì˜ê²Œ ì›ƒê³  ê³„ì‹œë‹ˆ ìì—°ì´ ì£¼ëŠ” í–‰ë³µì´ ëŠê»´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ì›ƒìŒ,ë“±ì‚°ë¡œ\", \"target_text\": \"ë“±ì‚°ë¡œì—ì„œ ì›ƒê³  ê³„ì‹œë‹ˆ ì‚°ì˜ ì•„ë¦„ë‹¤ì›€ì„ ë§Œë½í•˜ê³  ê³„ì‹  ê²ƒ ê°™ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ìŠ¤í¬ì¸  ê²½ê¸°ì¥\", \"target_text\": \"ìŠ¤í¬ì¸  ê²½ê¸°ì¥ì—ì„œ í–‰ë³µí•œ ëª¨ìŠµì´ ì •ë§ ì—´ì •ì ì´ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ì‚°ì† ì˜¤ë‘ë§‰\", \"target_text\": \"ì‚°ì† ì˜¤ë‘ë§‰ì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ íœ´ì‹ì´ ì •ë§ ì¦ê±°ì›Œ ë³´ì´ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,ìˆ˜ëª©ì›\", \"target_text\": \"ìˆ˜ëª©ì›ì—ì„œ ê¸°ìœ í‘œì •ì„ ë³´ë‹ˆ ìì—°ê³¼ í•¨ê»˜í•˜ëŠ” í–‰ë³µí•œ ì‹œê°„ì´êµ°ìš”!\"},\n",
    "    {\"input_text\": \"í™œë ¥,ìŠ¤ì¼€ì´íŠ¸ë³´ë“œ\", \"target_text\": \"ìŠ¤ì¼€ì´íŠ¸ë³´ë“œë¥¼ íƒ€ë©° í™œê¸°ì°¨ ë³´ì´ì‹œë„¤ìš”! ì •ë§ ì—ë„ˆì§€ê°€ ë„˜ì¹˜ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ê²¨ìš¸ ì‚°ì±…\", \"target_text\": \"ê²¨ìš¸ ì‚°ì±… ì¤‘ í–‰ë³µí•œ ëª¨ìŠµì´ ê²¨ìš¸ì˜ ì•„ë¦„ë‹¤ì›€ì„ ë”í•´ì£¼ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ì•„íŠ¸ ê°¤ëŸ¬ë¦¬\", \"target_text\": \"ì•„íŠ¸ ê°¤ëŸ¬ë¦¬ì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ ì˜ˆìˆ ì˜ í˜ì´ ëŠê»´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ì§€í•˜ì²  ì—­\", \"target_text\": \"ì§€í•˜ì²  ì—­ì—ì„œë„ ì¦ê±°ìš´ ëª¨ìŠµì´ ì¸ìƒì ì´ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,ì£¼ë§ ë§ˆì¼“\", \"target_text\": \"ì£¼ë§ ë§ˆì¼“ì—ì„œ ê¸°ìœ í‘œì •ì´ í–‰ë³µì„ ì „í•´ì£¼ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í™œë ¥,ë¬´ëŒ€\", \"target_text\": \"ë¬´ëŒ€ì—ì„œ í™œê¸°ì°¬ ëª¨ìŠµì´ ì •ë§ ë©‹ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ë†ì¥\", \"target_text\": \"ë†ì¥ì—ì„œ í–‰ë³µí•˜ê²Œ ì›ƒê³  ê³„ì‹œë‹ˆ ìì—°ê³¼ í•¨ê»˜í•˜ëŠ” ê¸°ì¨ì´ ëŠê»´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ë¡œë§¨í‹± ë ˆìŠ¤í† ë‘\", \"target_text\": \"ë¡œë§¨í‹± ë ˆìŠ¤í† ë‘ì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ íŠ¹ë³„í•œ ìˆœê°„ì´êµ°ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ì¹´ì•½\", \"target_text\": \"ì¹´ì•½ì„ ì¦ê¸°ë©° í–‰ë³µí•´ ë³´ì´ì‹œë„¤ìš”! ë¬¼ê³¼ í•¨ê»˜í•˜ëŠ” ì¦ê±°ìš´ ì‹œê°„ì´êµ°ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,í…Œë¼ìŠ¤\", \"target_text\": \"í…Œë¼ìŠ¤ì—ì„œ ê¸°ìœ í‘œì •ì„ ë³´ë‹ˆ ë©‹ì§„ ê²½ì¹˜ë¥¼ ë§Œë½í•˜ê³  ê³„ì‹œë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í™œë ¥,í—¬ìŠ¤ì¥\", \"target_text\": \"í—¬ìŠ¤ì¥ì—ì„œ í™œê¸°ì°¨ ë³´ì´ì‹œë„¤ìš”! ìš´ë™ í›„ì˜ ê¸°ì¨ì´ ì „í•´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ë‚˜ë¬´ ê·¸ëŠ˜\", \"target_text\": \"ë‚˜ë¬´ ê·¸ëŠ˜ì—ì„œ í–‰ë³µí•œ ëª¨ìŠµì„ ë³´ë‹ˆ ì—¬ìœ ë¡œìš´ ì‹œê°„ì´ ëŠê»´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ë¦¬ì¡°íŠ¸\", \"target_text\": \"ë¦¬ì¡°íŠ¸ì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ ì™„ë²½í•œ íœ´ì‹ì„ ì·¨í•˜ê³  ê³„ì‹œë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ë†€ì´ê³µì›\", \"target_text\": \"ë†€ì´ê³µì›ì—ì„œ ì¦ê±°ìš´ ëª¨ìŠµì´ ì •ë§ ì‹ ë‚˜ ë³´ì´ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,ê°•ê°€\", \"target_text\": \"ê°•ê°€ì—ì„œ ê¸°ìœ í‘œì •ì´ ë¬¼ê³¼ í•¨ê»˜í•˜ëŠ” í–‰ë³µì„ ë”í•´ì£¼ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í™œë ¥,ëŸ¬ë‹\", \"target_text\": \"ëŸ¬ë‹ ì¤‘ í™œê¸°ì°¬ ëª¨ìŠµì´ ì—ë„ˆì§€ë¥¼ ë¶ˆì–´ë„£ì–´ì£¼ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ì°¨ì–‘ ì•„ë˜\", \"target_text\": \"ì°¨ì–‘ ì•„ë˜ì—ì„œ í–‰ë³µí•œ ëª¨ìŠµì´ ì—¬ìœ ë¡œì›€ì„ ë”í•´ì£¼ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ì¶•ì œ\", \"target_text\": \"ì¶•ì œì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ ê¸°ìœ ë¶„ìœ„ê¸°ê°€ ì „í•´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ê³¨í”„ì¥\", \"target_text\": \"ê³¨í”„ì¥ì—ì„œ ì¦ê±°ì›Œí•˜ëŠ” ëª¨ìŠµì´ ì •ë§ í–‰ë³µí•´ ë³´ì´ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,ê´€ëŒì°¨\", \"target_text\": \"ê´€ëŒì°¨ì—ì„œ ê¸°ìœ í‘œì •ì´ ë†’ì€ ê³³ì—ì„œì˜ ì¦ê±°ì›€ì„ ì „í•´ì£¼ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í™œë ¥,ëŒ„ìŠ¤í™€\", \"target_text\": \"ëŒ„ìŠ¤í™€ì—ì„œ í™œê¸°ì°¨ ë³´ì´ì‹œë‹ˆ ì¶¤ì´ ì¦ê±°ìš´ ì‹œê°„ì„ ë§Œë“¤ì–´ì£¼ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,í–‡ë³• ì•„ë˜\", \"target_text\": \"í–‡ë³• ì•„ë˜ì—ì„œ í–‰ë³µí•œ ëª¨ìŠµì´ ìì—°ì˜ ì•„ë¦„ë‹¤ì›€ì„ ëŠë¼ê²Œ í•˜ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ìœ ì ì§€\", \"target_text\": \"ìœ ì ì§€ì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ ì—­ì‚¬ì™€ í•¨ê»˜í•˜ëŠ” ì¦ê±°ì›€ì´ ëŠê»´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ìŒì•…íšŒ\", \"target_text\": \"ìŒì•…íšŒì—ì„œ ì¦ê±°ìš´ ëª¨ìŠµì´ ë©‹ì§„ ê³µì—°ì„ ë§Œë½í•˜ê³  ê³„ì‹œë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,ì¡°ê¹… íŠ¸ë™\", \"target_text\": \"ì¡°ê¹… íŠ¸ë™ì—ì„œ ê¸°ì˜ê²Œ ë‹¬ë¦¬ì‹œë‹ˆ ê±´ê°•ê³¼ í–‰ë³µì´ ê°€ë“í•˜ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í™œë ¥,ìì—° íƒë°©\", \"target_text\": \"ìì—° íƒë°© ì¤‘ í™œê¸°ì°¬ ëª¨ìŠµì´ ëŒ€ìì—°ê³¼ì˜ ì¡°í™”ë¥¼ ëŠë¼ê²Œ í•˜ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ìº í•‘\", \"target_text\": \"ìº í•‘ ì¤‘ í–‰ë³µí•œ í‘œì •ì´ ìì—° ì†ì˜ íŠ¹ë³„í•œ ìˆœê°„ì„ ë§Œë“¤ì–´ì£¼ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ì»¤í”¼ìˆ\", \"target_text\": \"ì»¤í”¼ìˆì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ ë”°ëœ»í•œ ìŒë£Œì™€ í•¨ê»˜í•˜ëŠ” ì—¬ìœ ê°€ ëŠê»´ì§€ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ì²´í—˜ ë°•ëŒíšŒ\", \"target_text\": \"ì²´í—˜ ë°•ëŒíšŒì—ì„œ ì¦ê±°ìš´ ëª¨ìŠµì´ ìƒˆë¡œìš´ ê²½í—˜ì„ ë§Œë½í•˜ê³  ê³„ì‹œë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ê¸°ì¨,íŒ¨ì…˜ ë§¤ì¥\", \"target_text\": \"íŒ¨ì…˜ ë§¤ì¥ì—ì„œ ê¸°ìœ í‘œì •ì´ ìŠ¤íƒ€ì¼ì„ ì¦ê¸°ëŠ” ëª¨ìŠµì´ë„¤ìš”!\"},\n",
    "    {\"input_text\": \"í™œë ¥,ì˜¤í”ˆ ë§ˆì¼“\", \"target_text\": \"ì˜¤í”ˆ ë§ˆì¼“ì—ì„œ í™œê¸°ì°¨ ë³´ì´ì‹œë‹ˆ ë‹¤ì–‘í•œ ì¦ê±°ì›€ì„ ì°¾ê³  ê³„ì‹œêµ°ìš”!\"},\n",
    "    {\"input_text\": \"í–‰ë³µ,ì •ê¸€\", \"target_text\": \"ì •ê¸€ì—ì„œ í–‰ë³µí•œ í‘œì •ì„ ì§€ìœ¼ì‹œë‹ˆ ìì—°ì˜ ë§¤ë ¥ì„ ë§Œë½í•˜ê³  ê³„ì‹œë„¤ìš”!\"},\n",
    "    {\"input_text\": \"ë¯¸ì†Œ,ë¯¼ì†ì´Œ\", \"target_text\": \"ë¯¼ì†ì´Œì—ì„œ ë¯¸ì†Œë¥¼ ì§€ìœ¼ì‹œë‹ˆ ì „í†µì˜ ë§¤ë ¥ì„ ëŠë¼ê³  ê³„ì‹œêµ°ìš”!\"},\n",
    "    {\"input_text\": \"ì¦ê±°ì›€,ì•„ìš¸ë ›\", \"target_text\": \"ì•„ìš¸ë ›ì—ì„œ ì¦ê±°ì›Œí•˜ëŠ” ëª¨ìŠµì´ ì‡¼í•‘ì˜ ì¬ë¯¸ë¥¼ ë”í•´ì£¼ë„¤ìš”!\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.1 at http://localhost:6008/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard ì„œë²„ê°€ http://127.0.0.1:6006 ì—ì„œ ì‹¤í–‰ì¤‘.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# TensorBoard ì„œë²„ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)\n",
    "subprocess.Popen(['tensorboard', '--logdir=../model_follow_up/t5/logs', '--port=6100'])\n",
    "\n",
    "# TensorBoard ì„œë²„ê°€ ì‹œì‘ë˜ê¸°ë¥¼ ì ì‹œ ê¸°ë‹¤ë¦½ë‹ˆë‹¤\n",
    "time.sleep(5)\n",
    "\n",
    "# ì´í›„ TensorBoard ì„œë²„ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "print(\"TensorBoard ì„œë²„ê°€ http://127.0.0.1:6100 ì—ì„œ ì‹¤í–‰ì¤‘.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í›ˆë ¨ì‹œ ì ì • ì†ì‹¤ê°’ : 0.0001 ~ 0.0003\n",
    "https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/miniconda3/envs/project_3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:00<00:00, 4651.72 examples/s]\n",
      "/home/tommy/miniconda3/envs/project_3/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1300 07:16, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>20.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>17.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>13.353800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>9.971500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>7.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.255100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.882800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.778400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.623900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.490500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.475800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.413900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.206100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.207900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.173200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.075600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ì´ '../model_follow_up/t5/model'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "í† í¬ë‚˜ì´ì €ê°€ '../model_follow_up/t5/model/tokenizer'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('paust/pko-t5-base')\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_text': [item['input_text'] for item in data],\n",
    "    'target_text': [item['target_text'] for item in data]\n",
    "})\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples['input_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    labels = tokenizer(examples['target_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# ë°ì´í„°ì…‹ í† í°í™”\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# í•™ìŠµì¸ì\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=2,  # í•™ìŠµ ë°°ì¹˜ ì‚¬ì´ì¦ˆ\n",
    "    per_device_eval_batch_size=2,  # í‰ê°€ ë°°ì¹˜ ì‚¬ì´ì¦ˆ\n",
    "    output_dir='../t5',  # ëª¨ë¸ ë° ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "    num_train_epochs=50,  # í•™ìŠµ ì—í­ ìˆ˜\n",
    "    evaluation_strategy=\"no\",  # í‰ê°€ ì „ëµ ì„¤ì • (ì—¬ê¸°ì„œëŠ” í‰ê°€ë¥¼ í•˜ì§€ ì•ŠìŒ)\n",
    "    logging_dir='../t5/logs',  # TensorBoard ë¡œê·¸ê°€ ì €ì¥ë  ë””ë ‰í† ë¦¬\n",
    "    logging_steps=10,  # TensorBoard ë¡œê·¸ë¥¼ ê¸°ë¡í•  ê°„ê²© \n",
    "    report_to='tensorboard',  # TensorBoardë¡œ ë¡œê¹…\n",
    ")\n",
    "\n",
    "# Trainer ê°ì²´ ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "trainer.train()\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥\n",
    "model_save_path = '../model_follow_up/t5/model'\n",
    "tokenizer_save_path = '../model_follow_up/t5/model/tokenizer'\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "print(f\"ëª¨ë¸ì´ '{model_save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"í† í¬ë‚˜ì´ì €ê°€ '{tokenizer_save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ì…ë ¥: ê¸°ì¨, ê°•ì•„ì§€\n",
      "ëª¨ë¸ì˜ ì˜ˆì¸¡: ê°•ì•„ì§€ ë†ì¥ì—ì„œ ê¸°ìœ í‘œì •ì´ í–‰ë³µì„ ì „í•´ì£¼ë„¤ìš”!\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# ì €ì¥ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "model_save_path = '../model_follow_up/t5/model/'\n",
    "tokenizer_save_path = '../model_follow_up/t5/model/tokenizer/'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_save_path)\n",
    "tokenizer = T5TokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì…ë ¥\n",
    "test_input = \"ê¸°ì¨, ê°•ì•„ì§€\"\n",
    "# ì…ë ¥ í† í°í™”\n",
    "input_ids = tokenizer.encode(test_input, return_tensors='pt')\n",
    "\n",
    "# ëª¨ë¸ ì˜ˆì¸¡\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ë””ì½”ë”©\n",
    "predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì…ë ¥: {test_input}\")\n",
    "print(f\"ëª¨ë¸ì˜ ì˜ˆì¸¡: {predicted_text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
