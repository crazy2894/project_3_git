{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /mnt/e/py_data/project_3_git\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ì‘ì—… ê²½ë¡œ ì„¤ì •\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"project_3_git/readme.md\")\n",
    "notebook_dir = os.path.dirname(notebook_path)\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì¶œë ¥\n",
    "print(\"Current working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ê³µí¬, í—¤ë“œí°', 'ì•„ì°”í•œ ë¶„ìœ„ê¸°ë„¤ìš”! ğŸ§ ì–´ë–¤ ìŒì•… ë“£ê³  ê³„ì‹ ê°€ìš”? ê¶ê¸ˆí•´ìš”! ğŸ˜Š']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "import json\n",
    "\n",
    "# JSON íŒŒì¼ì—ì„œ ë”•ì…”ë„ˆë¦¬ ì½ê¸°\n",
    "with open('data/text_data/output_text.json', 'r') as file:\n",
    "    data_loaded = json.load(file)\n",
    "\n",
    "data_loaded['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [data_loaded[i][0] for i in data_loaded][:5000]\n",
    "train_y = [data_loaded[i][1] for i in data_loaded][:5000]\n",
    "test_x = [data_loaded[i][0] for i in data_loaded][5000:]\n",
    "test_y = [data_loaded[i][1] for i in data_loaded][5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['tensorboard', '--logdir=t5/transfer_1', '--...>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 10:37:22.817042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 10:37:22.834881: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 10:37:22.839826: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-03 10:37:22.852272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 10:37:23.630554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725327444.871511    8289 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725327445.186911    8289 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725327445.187034    8289 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.1 at http://localhost:4561/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Config ,T5TokenizerFast, T5ForConditionalGeneration, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "\n",
    "\n",
    "name_folder = 'transfer_1'\n",
    "server_port = '4561'\n",
    "batch_size = 16\n",
    "train_epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "# TensorBoard ì„œë²„ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)\n",
    "subprocess.Popen(['tensorboard', f'--logdir=t5/{name_folder}', f'--port={server_port}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ì¸ì ì¡°ì •\n",
    "- ë“œë¡­ ì•„ì›ƒ ë¹„ìœ¨ ì¡°ì • ê¸°ë³¸ê°’ : 0.1 -> 0.2\n",
    "- í•™ìŠµ ë¥  ì¡°ì •\n",
    "- ì›œ ì—… ìŠ¤í… ì„¤ì •\n",
    "- ë°°ì¹˜ ì‚¬ì´ì¦ˆ : ì½”ë©ì—ì„œ ëŒë¦´ë•Œ ì‹œë„\n",
    "- l2 ì •ê·œí™” (weight decay)\n",
    "- gredient clipping ê·¸ë¼ë””ì–¸íŠ¸ ì¡°ì •ìœ¼ë¡œ í•™ìŠµ ì•ˆì •í™” ì‹œí‚¤ê¸°\n",
    "- ë ˆì´ë¸” ìŠ¤ë¬´ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00<00:00, 8983.95 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 994/994 [00:00<00:00, 12174.41 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2570' max='18780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2570/18780 42:23 < 4:27:36, 1.01 it/s, Epoch 8.21/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.400500</td>\n",
       "      <td>0.327589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.210854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.187665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.182515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.180372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.179033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>0.178390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')\n",
    "config = T5Config.from_pretrained('paust/pko-t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('paust/pko-t5-base')\n",
    "\n",
    "config.dropout_rate = 0.2  # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ì„ 20%ë¡œ ì„¤ì • (ê¸°ë³¸ê°’ì€ 0.1)\n",
    "\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples['input_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    labels = tokenizer(examples['target_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„± ë° í† í°í™”\n",
    "dataset_train = Dataset.from_dict({'input_text': train_x,'target_text': train_y})\n",
    "dataset_test = Dataset.from_dict({'input_text': test_x,'target_text': test_y})\n",
    "\n",
    "tokenized_train_datasets = dataset_train.map(preprocess_function, batched=True)\n",
    "tokenized_test_datasets = dataset_test.map(preprocess_function, batched=True)\n",
    "\n",
    "# í•™ìŠµì¸ì\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=batch_size, # í•™ìŠµ ë°°ì¹˜ ì‚¬ì´ì¦ˆ\n",
    "    per_device_eval_batch_size=batch_size,  # í‰ê°€ ë°°ì¹˜ ì‚¬ì´ì¦ˆ\n",
    "    output_dir=f't5/{name_folder}',         # ëª¨ë¸ ë° ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬\n",
    "    num_train_epochs=train_epochs,          # í•™ìŠµ ì—í­ ìˆ˜\n",
    "    logging_dir=f't5/{name_folder}/logs',   # TensorBoard ë¡œê·¸ê°€ ì €ì¥ë  ë””ë ‰í† ë¦¬\n",
    "    logging_steps=100,                      # TensorBoard ë¡œê·¸ë¥¼ ê¸°ë¡í•  ê°„ê²© \n",
    "    report_to='tensorboard',                # TensorBoardë¡œ ë¡œê¹…\n",
    "    load_best_model_at_end = True,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',                  # ì—í¬í¬ ë§ˆë‹¤ ëª¨ë¸ ì €ì¥\n",
    "    # resume_from_checkpoint=True           # ì´ì–´ í•™ìŠµ\n",
    "\n",
    "    # ì¶”ê°€ ì¸ì\n",
    "    learning_rate=5e-5,                     # ê¸°ë³¸ê°’ì—ì„œ ì‹œì‘\n",
    "    lr_scheduler_type=\"linear\",             # ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "    warmup_steps=500,                       # 500 ìŠ¤í… ë™ì•ˆ í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€\n",
    "    weight_decay=0.01,                      # l2 ì •ê·œí™” ê¸°ë²• ì¤‘ í•˜ë‚˜\n",
    "    max_grad_norm=1.0,                      # ê·¸ë¼ë””ì–¸íŠ¸ í´ë¦¬í•‘\n",
    ")\n",
    "\n",
    "# Trainer ê°ì²´ ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_datasets,\n",
    "    eval_dataset=tokenized_test_datasets,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "trainer.train() # ì´ì–´ í•™ìŠµì‹œ (resume_from_checkpoint=checkpoint_dir)\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥\n",
    "model_save_path = f't5/{name_folder}/model'\n",
    "tokenizer_save_path = f't5/{name_folder}/model/tokenizer'\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "print(f\"ëª¨ë¸ì´ '{model_save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"í† í¬ë‚˜ì´ì €ê°€ '{tokenizer_save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5/transfer_0/model/')\n",
    "tokenizer = T5TokenizerFast.from_pretrained('t5/transfer_0/model/tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ŒìŠ¤íŠ¸ ì…ë ¥: ì•¼!!!!\n",
      "ëª¨ë¸ì˜ ì˜ˆì¸¡: ì •ë§ í™”ê°€ ë‚˜ì‹  ê²ƒ ê°™ì•„ìš”! ğŸ˜  ì–´ë–¤ ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì…ë ¥\n",
    "test_input = \"ì•¼!!!!\"\n",
    "\n",
    "# ì…ë ¥ í† í°í™”\n",
    "input_ids = tokenizer.encode(test_input, return_tensors='pt')\n",
    "\n",
    "# GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³ , ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° GPUë¡œ ì´ë™\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ GPUë¡œ ì´ë™\n",
    "model.to(device)\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„°ë„ GPUë¡œ ì´ë™\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "# ì˜ˆì¸¡ì„ GPUì—ì„œ ìˆ˜í–‰\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ë””ì½”ë”©\n",
    "predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì…ë ¥: {test_input}\")\n",
    "print(f\"ëª¨ë¸ì˜ ì˜ˆì¸¡: {predicted_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
