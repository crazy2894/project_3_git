# SNS ì‚¬ì§„ ë¶„ì„ ëŒ“ê¸€ ë° í”¼ë“œë°± í”„ë¡œì íŠ¸

- íŒŒì´ì¬ ë²„ì „
    ```bash
    conda create -n project_3 python==3.11
    ```
- íŒ¨í‚¤ì§€ ì„¤ì¹˜
    ```bash
    git clone https://github.com/crazy2894/project_3_git.git
    cd project_3_git
    pip install -r requiremets.txt
    ```

#### ê³µí†µ ì‚¬í•­
**ëª¨ë“  ëª¨ë¸ì—ì„œ earlystopping ,patient = 10 ì´ìš©**<br>
**(Faster R-CNN ì œì™¸ : ì»¤ìŠ¤í…€ ealrystop ìš”êµ¬)**

## to do list ë° ckeck list

- ê³µì‹ tta ì„±ëŠ¥ì§€í‘œ í™•ì¸ í›„ ì ìš© ê°€ëŠ¥ì‹œ ì ìš©ì‹œ ë¹„êµ **ì§„í–‰ì¤‘**
- ~~ê°ê° ì™œ ì´ ëª¨ë¸ì„ ì¼ëŠ”ì§€ ì •í™•í•œ ì‚¬í•­ ê¸°ì¬~~ **ì™„ë£Œ**
- ì§€í‘œ ë° ì„±ê³¼ ë˜í•œ ì •í™•íˆ ê³µì‹ tta ê¸°ì¤€ í™•ì¸í›„ ë¹„êµ ì§€í‘œë¡œ ì§€ì • **ì§„í–‰ì¤‘**
- 15 ë¶„ ë°œí‘œ ì‹œê°„ ë§ì¶”ê¸°
í˜„ì—… ì‚¬ì—… ìš©ì—­ : 
https://vercel.com/docs
https://vast.ai/pricing
https://www.wishket.com/partners/
https://cs.tta.or.kr/tta/introduce/introListR.do
https://www.perplexity.ai/

- ê³µì‹ tta ì„±ëŠ¥ì§€í‘œ í™•ì¸ í›„ ì ìš© ê°€ëŠ¥ì‹œ ì ìš©ì‹œ ë¹„êµ

- ~~ì™œ ì´ ëª¨ë¸ë“¤ì„ ì¼ëŠ”ì§€ ì •í™•íˆ~~ ì™„ë£Œ
- ì„±ê³¼ ì§€í‘œ ì •í™•íˆ
- 15 ë¶„

### what to do
2024 - 09 - 08 : yolo ë° ssd í‰ê°€ì§€í‘œ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ê¸°


# Oject Detection + classification ëª¨ë¸
### ì‚¬ìš© ëª¨ë¸ ë° ì´ìœ  : 
#### ì˜¤ë¸Œì íŠ¸ ë””í…ì…˜ ëª¨ë¸
- detectron2 : https://github.com/facebookresearch/detectron2
  - faster_rcnn_R_50_FPN_3x : ì–¼êµ´ ë°ì´í„° ê°ì • ë¶„ë¥˜ **ì „ì´ í•™ìŠµ**
    ```
    **ì „ì´ í•™ìŠµ**
    ë†’ì€ ì •í™•ë„, ê°ì • ë¶„ë¥˜ì— ì´ìš©, Yolo ì™€ ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•´ ì‚¬ìš© ë¨
    ```

- ultralytics : https://www.ultralytics.com/ko
  - [yolov10n](https://github.com/THU-MIG/yolov10) : ì–¼êµ´ ë°ì´í„° ê°ì • ë¶„ë¥˜ **ì „ì´ í•™ìŠµ**
    ```
    **ì „ì´ í•™ìŠµ**
    ë¹ ë¥¸ ì¶”ë¡  ë° ì‹¤ì‹œê°„ ê°ì •ë¶„ë¥˜ ê°€ëŠ¥, ì ì€ ë¹„ìš©ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ëƒ„, SOTA ëª¨ë¸
    ```
  - [yolov8x-oiv7](https://docs.ultralytics.com/ko/datasets/detect/open-images-v7/#open-images-v7-pretrained-models) 
    ```
    **ì‚¬ì „ í•™ìŠµ ëª¨ë¸**
    ê°ì²´ ê²€ì¶œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì´ìš©
    ì‰½ê²Œ ë¶ˆëŸ¬ì™€ ì‚¬ìš© ê°€ëŠ¥ í•˜ë‹¤
    ```

#### ì–¸ì–´ ëª¨ë¸(Transformer based) :
- T5 **ì „ì´ í•™ìŠµ**
  - T5-base : https://huggingface.co/paust/pko-t5-base
  - T5-large : https://huggingface.co/paust/pko-t5-large
  ```
  **ì „ì´ í•™ìŠµ**
  ê³µí†µ : ìƒëŒ€ì ìœ¼ë¡œ LLM ë³´ë‹¤ ì‘ì€ ëª¨ë¸ì„ì—ë„ ì •í•´ì§„ í…ŒìŠ¤í¬ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì„
  ë¹„êµë¥¼ ìœ„í•´ base ëª¨ë¸ê³¼ large ëª¨ë¸ ì´ìš©
  ```
- gpt2 **ì „ì´ í•™ìŠµ**
  - kogpt2 : https://huggingface.co/skt/kogpt2-base-v2
  - gpt2 : https://huggingface.co/openai-community/gpt2
  ```
  **ì „ì´ í•™ìŠµ**
  ê³µí†µ : íŠ¸ëœìŠ¤ ëª¨ë¸ ê¸°ë°˜ì˜ ëª¨ë¸ë¡œ, ììœ ë¡œìš´ í…ìŠ¤íŠ¸ ìƒì„± ëŠ¥ë ¥ì´ ë›°ì–´ë‚¨ llmë“¤ì˜ ì´ˆê¸°ëª¨ë¸.
  kogpt2 : í•œêµ­ì–´ì— íŠ¹í™”ëœ gpt2 ëª¨ë¸. í•œêµ­ì–´ì— ëŒ€í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ìƒì„± ì˜ˆìƒ.
  gpt2 : í•œêµ­ì–´ ëª¨ë¸ê³¼ ë¹„êµ.
  ```

### [api : ë°ì´í„° ìƒì„±](code_data_gen/3_textdata_generating.ipynb)
- chat gpt4o-mini
  ```
  ê¸°ì¡´ chat gpt4 ì— ë¹„í•´ ì €ë ´í•˜ë‹¤.
  ```
- gemini-1.5-flash
  ```
  ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥. í•˜ì§€ë§Œ ìš”ì²­ íšŸìˆ˜ê°€ ì œí•œë˜ì–´ ìˆë‹¤(15 ìš”ì²­/ë¶„)
  ```
### ì‚¬ìš© ë°ì´í„° ì…‹ :
- ì´ë¯¸ì§€ ë°ì´í„° ì…‹: wassup ì•ˆë©´ ë°ì´í„°
  - ê¸°ë³¸ json í˜•ì‹ì„ yolo í˜•ì‹ìœ¼ë¡œ annotation ë³€í™˜ : [ì½”ë“œ](code/1_2ë°ì´í„°_ì „ì²˜ë¦¬_yolo.ipynb)
  - yolo í˜•ì‹ì—ì„œ COCOë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜ : [ì½”ë“œ](code/1_3ë°ì´í„°_ì „ì²˜ë¦¬_ssd,rcnn.ipynb)

- í…ìŠ¤íŠ¸ ë°ì´í„° ì…‹ : ì¶œë ¥ëœ ì´ë¯¸ì§€ ë¼ë²¨[ê°ì • ë¶„ë¥˜ ë° ,yolov8x-oiv7 ì¶œë ¥] ì„ ì´ìš©í•˜ì—¬ ìƒì„± : [ì½”ë“œ](code_data_gen/3_textdata_generating.ipynb)
  - gemini ë° gpt api ì´ìš© ë° í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
    ```py
    def prompting(input_):
      return f"""
    ì‚¬ì§„ì— ëŒ€í•œ ëŒ“ê¸€ ì…ë ¥
    ì§ˆë¬¸ ê¸ˆì§€
    sns ì‚¬ì§„ ìš”ì†Œ : 'ë¶„ë…¸, ì—¬ì, ì¸ê°„ì˜ ì–¼êµ´, ê³µ, ì˜ë¥˜'
    sns ëŒ“ê¸€ : í™”ê°€ ë‚œ ë“¯í•œ í‘œì •ì´ë„¤! ğŸ€ ê³µì€ ë¬´ìŠ¨ ì¢…ë¥˜ì•¼? ì˜·ë„ ë©‹ì§€ë‹¤! ğŸ˜Š
    
    ì˜ˆì¸¡ í•œ ë¬¸ì¥
    sns ì‚¬ì§„ ìš”ì†Œ : {input_}
    sns ëŒ“ê¸€ : """
    ```
# ëª¨ë¸ í•™ìŠµ ë° ê²°ê³¼

## ì„±ê³¼ ì„±ëŠ¥ ì§€í‘œ ì„¤ì •

### ì–¸ì–´ ëª¨ë¸ : BLEU-N, METEOR, ROUGE-N
### ê°ì²´ íƒì§€ ëª¨ë¸ : Macro Average, Weighted Average, Micro Average

ì°¸ì¡° : https://test.tta.or.kr/tta/main/main.do

## Obect Detection 1 : Faster R-CNN
### detectron2 from facebook
- ê¸°ë³¸ì ìœ¼ë¡œ detectron2 ì˜ faster-rcnn ì„ ì´ìš©í•¨
  ```bash
  git clone https://github.com/facebookresearch/detectron2.git
  python -m pip install -e detectron2
  ```

### ìµœì¢… ê²°ê³¼
```
- ì†Œìš” ì‹œê°„ : ì•½ 7000 step / 5.12 ì‹œê°„
- í•„ìš” ë¦¬ì†ŒìŠ¤ : ì•½ 4GBì˜ ë©”ëª¨ë¦¬
- ìµœì¢… metrics : mAP50 87.23 %
```

###  [**ë°ì´í„° ì „ì²˜ë¦¬**](code/1_3ë°ì´í„°_ì „ì²˜ë¦¬_ssd,rcnn.ipynb)
```
ê¸°ë³¸ ì ìœ¼ë¡œ COCO ë°ì´í„° ì…‹ê³¼ë™ì¼í•œ í˜•ì‹
ë¬¸ì œ : ì‚¬ì§„ì˜ width ì™€ heightë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ ì˜¬ë°”ë¥´ê²Œ ë¶ˆëŸ¬ì™€ ì§€ì§€ ì•ŠìŒ
í•´ê²° : => exif ë¥¼ ì´ìš©í•˜ì—¬ íšŒì „ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì ìš©í•¨
```
- ì „ì²˜ë¦¬ ì½”ë“œ í•¨ìˆ˜ ì •ì˜
  ```py

    def read_image_size_from_exif(image_path):
      with Image.open(image_path) as img:
          # EXIF ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
          exif = img._getexif()

          # EXIF ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ í¬ê¸° ë°˜í™˜
          if exif is None:
              return img.size

          # Orientation íƒœê·¸ ê°€ì ¸ì˜¤ê¸°
          orientation_key = [key for key, val in TAGS.items() if val ==   'Orientation'][0]
          orientation = exif.get(orientation_key, 1)  # EXIFì—ì„œ Orientation  ê°’ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 1ì„ ì‚¬ìš©

          # Orientationì— ë”°ë¼ ì´ë¯¸ì§€ íšŒì „
          if orientation == 3:
              img = img.rotate(180, expand=True)
          elif orientation == 6:
              img = img.rotate(270, expand=True)
          elif orientation == 8:
              img = img.rotate(90, expand=True)

          # íšŒì „ëœ í›„ì˜ ì´ë¯¸ì§€ í¬ê¸° ë°˜í™˜
          return img.size
  # ì´í›„ YOLO í˜•ì‹ì˜ annotation => COCO í˜•ì‹ì˜ annotation
  ```
###  [**í›ˆë ¨ ì½”ë“œ**](code/2_RCNN_0_transfer.ipynb)
  - ì„¤ì • í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì„¤ëª…
    ```py
    cfg = get_cfg()

    # ì–´ë–¤ ë°±ë³¸ ëª¨ë¸ì„ ì´ìš©í• ì§€ ì„¤ì • (í˜„ì œ ì„¤ì •ê°’ : resnet-50) ì¶”ê°€ ë°±ë³¸ í™•ì¸
    #https://github.com/facebookresearch/detectron2/tree/main/configs/COCO-Detection
    cfg.merge_from_file("detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")
    # ë°ì´í„° ì…‹ ì„¤ì •
    cfg.DATASETS.TRAIN = ("face_data_set",)
    cfg.DATASETS.TEST = ("face_data_set_valid",)

    # ë°ì´í„° ë¡œë”© ì‚¬ìš© í”„ë¡œì„¸ì„œ ìˆ˜
    cfg.DATALOADER.NUM_WORKERS = 2

    # ì´ˆê¸° ê°€ì¤‘ì¹˜ COCO ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ í•™ìŠµëœ Mask R-CNN ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©
    cfg.MODEL.WEIGHTS = "detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl"
    
    # ê° ë°°ì¹˜(batch)ë‹¹ ì´ë¯¸ì§€ ìˆ˜ë¥¼ ì§€ì •
    cfg.SOLVER.IMS_PER_BATCH = 16

    # í•™ìŠµì˜ ê¸°ë³¸ í•™ìŠµë¥ (learning rate)ì„ ì§€ì •
    cfg.SOLVER.BASE_LR = 0.001
    # ìµœëŒ€ í•™ìŠµ ë°˜ë³µ íšŸìˆ˜(iterations)ë¥¼ ì§€ì •
    cfg.SOLVER.MAX_ITER = 1000

    # ì‚¬ì§„ ë¦¬ ì‚¬ì´ì§• (yolo ì™€ ê°™ì€ ë¹„êµë¥¼ ìœ„í•´)
    cfg.INPUT.MIN_SIZE_TRAIN = 512
    cfg.INPUT.MAX_SIZE_TRAIN = 512
    cfg.INPUT.MIN_SIZE_TEST = 512
    cfg.INPUT.MAX_SIZE_TEST = 512

    # ë°ì´í„° ì¦ê°•
    cfg.INPUT.RANDOM_FLIP = "horizontal"
    cfg.INPUT.RANDOM_ROTATION = 30
    cfg.INPUT.CROP = CN({"ENABLED": True, "TYPE": "relative_range", "SIZE": [0.8, 0.8]})

    # Region Of Interest ë°°ì¹˜ í¬ê¸° ì§€ì • ë° í´ë˜ìŠ¤ ê°œìˆ˜ ì§€ì •
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4

    # ì¶œë ¥
    cfg.OUTPUT_DIR = "./models/faster_rcnn_R_50_FPN_3x"

    # í‰ê°€ / iter
    cfg.TEST.EVAL_PERIOD = 1000

    # ì €ì¥ / iter
    cfg.SOLVER.CHECKPOINT_PERIOD = 500

    # ì›œì—… iter ì •í•˜ê³  ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë¦„ ì •í•˜ê¸°
    cfg.SOLVER.LR_SCHEDULER_NAME = "WarmupCosineLR"
    cfg.SOLVER.WARMUP_ITERS = 500
    ```
### ë°”ìš´ë”© ë°•ìŠ¤ ë©”íŠ¸ë¦­
![rcnn_bb_mat](models/faster_rcnn_R_50_FPN_3x/metric_graphs/box_losses.png)
1. **loss_box_reg (ë°•ìŠ¤ íšŒê·€ ì†ì‹¤)**:
   - ì „ì²´ì ìœ¼ë¡œ ê°ì†Œí•˜ëŠ” ì¶”ì„¸ë¥¼ ë³´ì´ê³  ìˆìŒ.
   - ì´ˆê¸°ì ì¸ ê°’ì€ 0.15 ì •ë„ì˜€ìœ¼ë‚˜, ì ì  ë‚®ì•„ì ¸ 0.09 ê·¼ì²˜ë¡œ ì•ˆì •í™”ë˜ê³  ìˆìŒ.
   - ì´ëŠ” ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë°•ìŠ¤ì™€ ì‹¤ì œ ë°•ìŠ¤ ê°„ì˜ ì°¨ì´ë¥¼ ì¤„ì´ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•¨.

2. **loss_rpn_cls (RPN í´ë˜ìŠ¤ ì†ì‹¤)**:
   - ì´ ì†ì‹¤ ë˜í•œ ê°ì†Œí•˜ê³  ìˆì§€ë§Œ, ì¤‘ê°„ì— ì•½ê°„ì˜ ë³€ë™ì„±ì´ ìˆìŒ.
   - ì´ˆê¸°ì—ëŠ” ì•½ 0.00012 ë¶€ê·¼ì—ì„œ ì‹œì‘í–ˆìœ¼ë©°, ê²°êµ­ 0.00004ë¡œ ë–¨ì–´ì§.
   - RPNì˜ í´ë˜ìŠ¤ ì˜ˆì¸¡ ì •í™•ì„±ì´ í–¥ìƒë˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ„.

3. **loss_rpn_loc (RPN ìœ„ì¹˜ ì†ì‹¤)**:
   - ì´ ì†ì‹¤ì€ ì „ì²´ì ìœ¼ë¡œ ì ì§„ì ìœ¼ë¡œ ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ìˆìŒ.
   - ì´ˆê¸° ê°’ì€ ì•½ 0.0018ì—ì„œ ì‹œì‘í•˜ì—¬ í˜„ì¬ëŠ” 0.0012 ì •ë„ê°€ ë˜ì–´, ì œì•ˆëœ ì§€ì—­ì˜ ìœ„ì¹˜ ì˜ˆì¸¡ì´ ì •í™•í•´ì§€ê³  ìˆìŒì„ ë³´ì—¬ì¤Œ.

#### ìš”ì•½
ì¢…í•©ì ìœ¼ë¡œ, ì„¸ ê°€ì§€ ì†ì‹¤ ëª¨ë‘ ê°ì†Œí•˜ëŠ” ì¶”ì„¸ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì´ ì ì°¨ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ„. í›ˆë ¨ì´ ì§„í–‰ë¨ì— ë”°ë¼ ì†ì‹¤ ê°’ë“¤ì´ ì•ˆì •í™”ë˜ê³  ìˆìŒì„ í†µí•´ íš¨ê³¼ì ì¸ í•™ìŠµì´ ì´ë£¨ì–´ì§€ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŒ.


<details>
  <summary>ìµœì¢… ê²°ê³¼ metrics</summary>

- ìµœì¢… ê²°ê³¼ metrics
  | Metric                           | Value                      |
  |----------------------------------|----------------------------|
  | bbox/AP                          | 74.22026                   |
  | bbox/AP-angry                    | 71.10707                   |
  | bbox/AP-happy                    | 82.11466                   |
  | bbox/AP-sad                      | 72.93612                   |
  | bbox/AP-surprised                | 70.72321                   |
  | bbox/AP50                        | 87.23360                   |
  | bbox/AP75                        | 86.68937                   |
  | bbox/APl                         | 74.22026                   |
  | bbox/APm                         | 0                          |
  | bbox/APs                         | 0                          |
  | data_time                        | 1.57703                    |
  | eta_seconds                      | 1503805.92043              |
  | fast_rcnn/cls_accuracy           | 0.97681                    |
  | fast_rcnn/false_negative         | 0.01034                    |
  | fast_rcnn/fg_cls_accuracy        | 0.91069                    |
  | iteration                        | 6999                       |
  | loss_box_reg                     | 0.11586                    |
  | loss_cls                         | 0.05802                    |
  | loss_rpn_cls                     | 0.00005                    |
  | loss_rpn_loc                     | 0.00145                    |
  | lr                               | 0.0009997                  |
  | rank_data_time                   | 1.57703                    |
  | roi_head/num_bg_samples           | 103.09375                  |
  | roi_head/num_fg_samples           | 24.90625                  |
  | rpn/num_neg_anchors              | 252.15625                  |
  | rpn/num_pos_anchors              | 3.84375                   |
  | time                             | 2.52261                    |
  | total_loss                       | 0.17474                    |

</details>

#### ap ì— ëŒ€í•œ ì§€í‘œ
**[logs](logs/eval_validateion_of_rcnn.log)** <br>
**[codes](code_metric_check/_Avarage%20Precision.ipynb)**
```py
Average Precision [ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.742
Average Precision [ IoU=0.50      | area=   all | maxDets=100 ] = 0.872
Average Precision [ IoU=0.75      | area=   all | maxDets=100 ] = 0.867
Average Precision [ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
Average Precision [ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
Average Precision [ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742
Average Recall    [ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.859
Average Recall    [ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.860
Average Recall    [ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860
Average Recall    [ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
Average Recall    [ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000
Average Recall    [ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.860
```
## Obect Detection 2 : YoLOv10
### ê¸°ë³¸ ì •ë³´
```
- ì†Œìš” ì‹œê°„ : ì•½ 7 ì‹œê°„ (ì´ 63 ì—í¬í¬) - early stopping ê¹Œì§€ì˜ ì‹œê°„
- early stopping petient : 10
- í•„ìš” ë¦¬ì†ŒìŠ¤ : ì•½ 4GBì˜ ë©”ëª¨ë¦¬
- ìµœì¢… metrics : mAP50 89.81 %
```

### [**ë°ì´í„° ì „ì²˜ë¦¬**](code/1_2ë°ì´í„°_ì „ì²˜ë¦¬_yolo.ipynb)
  ```py
  json í˜•ì‹ì˜ íŒŒì¼ì„ íŒŒì¼ í•˜ë‚˜ í•˜ë‚˜ ë¶„ë¦¬í•˜ì—¬ ë™ì¼ í´ë”ì— ë™ì¼ ì´ë¦„ìœ¼ë¡œ txt íŒŒì¼ë¡œ ì €ì¥
  ê¸°ë³¸ì ì¸ ì ˆëŒ€ ìœ„ì¹˜ì˜ í˜•ì‹ì„ yolo ì—ì„œ ìš”êµ¬í•˜ëŠ” ìƒëŒ€ ì¤‘ì‹¬ ìœ„ì¹˜ì™€ ìƒëŒ€ ë°•ìŠ¤ í¬ê¸°ë¡œ ì§€ì • í•˜ì˜€ìŒ
  ```
  - ì „ì²˜ë¦¬ ì½”ë“œ í•¨ìˆ˜ ì •ì˜
    ```py
    def convert_bbox_to_yolo_format(image_size, bbox):
      """
      ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
      :param image_size: (width, height) ì´ë¯¸ì§€ í¬ê¸°
      :param bbox: {'minX': float, 'minY': float, 'maxX': float, 'maxY': float} ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
      :return: (x_center, y_center, width, height) YOLO í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤
      """
      dw = 1.0 / image_size[0]
      dh = 1.0 / image_size[1]
      x_center = (bbox['minX'] + bbox['maxX']) / 2.0
      y_center = (bbox['minY'] + bbox['maxY']) / 2.0
      width = bbox['maxX'] - bbox['minX']
      height = bbox['maxY'] - bbox['minY']

      # YOLO í˜•ì‹ì— ë§ê²Œ ì¢Œí‘œë¥¼ ì •ê·œí™”
      x_center = x_center * dw
      y_center = y_center * dh
      width = width * dw
      height = height * dh

      return (x_center, y_center, width, height)
    ```
  - ì „ì²˜ë¦¬ í›„ íŒŒì¼ ì €ì¥ í•¨ìˆ˜ ì •ì˜
    ```py
    def save_annotations(json_data, output_dir, image_size):
    """
    ì´ë¯¸ì§€ë¥¼ yolo ì— ë§ê²Œ
    txt íŒŒì¼ ìƒì„± (ìœ„ì˜ í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì™€ í˜•ì‹ ë³€í™˜ í›„ ì €ì¥.)
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for item in json_data:
        image_file = item['filename']
        image_name, _ = os.path.splitext(image_file)
        txt_file_path = os.path.join(output_dir, f"{image_name}.txt")
        
        with open(txt_file_path, 'w') as f:
            # Iterate over annotations (A, B, C)
            annot = item.get('annot_A')
            print(annot)
            if annot:
                bbox = annot['boxes']
                face_exp = item['faceExp_uploader']
                class_id = class_to_id.get(face_exp, -1)
                if class_id == -1:
                    class_id = 3
                print(class_id)
                if class_id != -1:
                    yolo_bbox = convert_bbox_to_yolo_format(image_size, bbox)
                    print(yolo_bbox)
                    f.write(f"{class_id} {' '.join(map(str, yolo_bbox))}\n")
                    print(f"{class_id} {' '.join(map(str, yolo_bbox))}\n")
    ```
  - yaml íŒŒì¼ ìƒì„±
    ```text
    train: ./data/yolo_data/train
    val: ./data/yolo_data/val
    nc: 4
    names: ['anger', 'sad', 'panic', 'happy']
    ```

### [**í›ˆë ¨ ì½”ë“œ**](code/2_YOLO_1_transfer_1.ipynb)
```py
from ultralytics.models import YOLOv10

model_for_trian = YOLOv10("models/yolov10/pt_models/yolov10n.pt")
model_for_trian.train(data="wassup_data.yaml", epochs=10000, imgsz=512, patience=10)
```
- ì†Œìš” ì‹œê°„ : gpu 3060 - 63 epochs completed in 6.935 hours.
### ë°”ìš´ë”© ë°•ìŠ¤ ë©”íŠ¸ë¦­
  ![epoch](models/yolov10/runs/detect/train/val_losses_comparison.png)

  1. **val/box_om (ìƒë‹¨ ì™¼ìª½)**:
    - ì´ˆê¸°ì—ëŠ” 0.70 ìˆ˜ì¤€ì—ì„œ ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ê°ì†Œí•¨.
    - ì•½ 10 ì—í¬í¬ ì´í›„ ì•ˆì •ì ì¸ ìˆ˜ì¤€ìœ¼ë¡œ ê°ì†Œí•˜ì—¬ 0.54 ê·¼ì²˜ë¡œ ìˆ˜ë ´í•˜ê³  ìˆìŒ.
    - ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë°•ìŠ¤ì˜ ì •í™•ë„ê°€ í–¥ìƒë˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ„.

  2. **val/cls_om (ìƒë‹¨ ì¤‘ì•™)**:
    - ì´ ì†ì‹¤ ì—­ì‹œ ì´ˆê¸°ì—ëŠ” 1.6 ì´ìƒìœ¼ë¡œ ì‹œì‘í•˜ì˜€ìœ¼ë‚˜, ì´í›„ ê¸‰ê²©íˆ ê°ì†Œí•˜ì—¬ 0.6 ì´í•˜ë¡œ ë–¨ì–´ì§.
    - ì—í¬í¬ 20 ì´í›„ì—ëŠ” ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ê³  ìˆìœ¼ë©°, ëª¨ë¸ì˜ í´ë˜ìŠ¤ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ê°œì„ ëœ ê²ƒì„ ì˜ë¯¸í•¨.

  3. **val/dfl_om (ìƒë‹¨ ì˜¤ë¥¸ìª½)**:
    - ì´ˆê¸°ì—ëŠ” 1.0 ì •ë„ì—ì„œ ì‹œì‘í•˜ì˜€ê³ , ì—í¬í¬ê°€ ì§„í–‰ë¨ì— ë”°ë¼ ì„œì„œíˆ ì¦ê°€í•˜ì—¬ 1.01 ìˆ˜ì¤€ê¹Œì§€  ì˜¬ë¼ê°”ìŒ.
    - ì „ì²´ì ìœ¼ë¡œ ì•ˆì •ì„¸ë¥¼ ë³´ì´ê³  ìˆìŒ.

  4. **val/box_oo (í•˜ë‹¨ ì™¼ìª½)**:
    - ì´ˆê¸° ê°’ì´ ì•½ 0.75ì—ì„œ ì¶œë°œí•˜ì—¬ ë¹ ë¥¸ ì†ë„ë¡œ ê°ì†Œí•¨.
    - ì•½ 10 ì—í¬í¬ í›„ 0.55 ìˆ˜ì¤€ìœ¼ë¡œ ì•ˆì •í™”ë˜ê³ , ë°•ìŠ¤ ì˜ˆì¸¡ ì„±ëŠ¥ì´ í–¥ìƒëœ ê²ƒì„ ë³´ì—¬ì¤Œ.

  5. **val/cls_oo (í•˜ë‹¨ ì¤‘ì•™)**:
    - ì´ˆê¸° ê°’ì´ 3.5 ì •ë„ì—ì„œ ì‹œì‘í•˜ì˜€ìœ¼ë©°, ê¸‰ê²©íˆ ê°ì†Œí•˜ì—¬ 0.5 ê·¼ì²˜ë¡œ ì•„ ë–¨ì–´ì§.
    - ëª¨ë¸ì˜ í´ë˜ìŠ¤ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ëˆˆì— ë„ê²Œ í–¥ìƒë˜ì—ˆìŒì„ ë‚˜íƒ€ëƒ„.

  6. **val/dfl_oo (í•˜ë‹¨ ì˜¤ë¥¸ìª½)**:
    - ì´ˆê¸°ì—ëŠ” 0.93 ì •ë„ì—ì„œ ì¶œë°œí•˜ì—¬ ì´í›„ ì ì§„ì ìœ¼ë¡œ ê°ì†Œí•˜ì—¬ 0.88 ìˆ˜ì¤€ê¹Œì§€ ë–¨ì–´ì§.
    - ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ê¾¸ì¤€íˆ ê°œì„ ë˜ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ.

#### ìš”ì•½:
![prgraph](models/yolov10/runs/detect/train/PR_curve.png)
ì „ì²´ ê·¸ë˜í”„ì—ì„œ ë³´ì´ëŠ” ê²½í–¥ì€ ì†ì‹¤ ê°’ë“¤ì´ ê°ì†Œí•˜ê³  ìˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ê°œì„ ë˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ„. íŠ¹íˆ í´ë˜ìŠ¤ ì†ì‹¤ê³¼ ë°•ìŠ¤ ì†ì‹¤ì˜ ê°ì†ŒëŠ” ëª¨ë¸ì˜ ì˜ˆì¸¡ ì •í™•ë„ê°€ í–¥ìƒë˜ê³  ìˆë‹¤ëŠ” ê¸ì •ì ì¸ ì‹ í˜¸ì„. ê° ì—í¬í¬ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ê°€ ì•ˆì •ì ì´ê¸° ë•Œë¬¸ì— í•™ìŠµ ê³¼ì •ì´ íš¨ê³¼ì ìœ¼ë¡œ ì§„í–‰ë˜ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŒ.

<details>
  <summary>ìµœì¢… ê²°ê³¼ metrics</summary>

ìµœì¢… ê²°ê³¼ metrics ë¡œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
| Metric                    | Value    |
|---------------------------|----------|
| Epoch                     | 53       |
| Train Box OM              | 0.62436  |
| Train Class OM            | 0.58579  |
| Train DFL OM              | 0.99884  |
| Train Box OO              | 0.69133  |
| Train Class OO            | 0.57590  |
| Train DFL OO              | 0.94041  |
| Metrics Precision (B)     | 0.86438  |
| Metrics Recall (B)        | 0.80065  |
| Metrics mAP50 (B)         | 0.89814  |
| Metrics mAP50-95 (B)      | 0.78219  |
| Validation Box OM         | 0.53624  |
| Validation Class OM       | 0.55669  |
| Validation DFL OM         | 1.00460  |
| Validation Box OO         | 0.54794  |
| Validation Class OO       | 0.53841  |
| Validation DFL OO         | 0.88608  |
| Learning Rate PG0         | 0.0099495|
| Learning Rate PG1         | 0.0099495|
| Learning Rate PG2         | 0.0099495|

</details>

## object detection ì„±ê³¼ ì§€í‘œ ë¹„êµ
ğŸ¿**[APcalc code](code_metric_check/_Avarage%20Precision.ipynb)**ğŸ¿
- **Average Precision at IoU 50 and 50-95**<br>
  - ê²€ì¦ ë°ì´í„° ì •ë³´ val dataset test
    ```
    ë°ì´í„° ì…‹: wassup ì–¼êµ´ ë°ì´í„° ì…‹
    ì´ ê°¯ìˆ˜ : 1199 ê°œì˜ ì‚¬ì§„ ë°ì´í„°
    ë¼ë²¨ ê°¯ìˆ˜ : 
      anger : 300
        sad : 300
      panic : 300
      happy : 299
    ```

  | í•­ëª©| YOLOv10n| RCNN|
  |---|---|---|
  | **AP 50**| **89.81**| **87.23**|
  | **AP 50-95** | **78.22** | **74.20** |
  | **time** |**1m 17s**|**2m 57s**|

### ê²°ë¡ 
- **YOLOv10n**ì€ AP 50 ë° AP 50-95 ëª¨ë‘ RCNNë³´ë‹¤ ì„±ëŠ¥ì´ ìš°ìˆ˜.
- ì´ëŠ” **YOLOv10n**ì´ ë‹¤ì–‘í•œ ê°ì²´ ê°ì§€ ìƒí™©ì—ì„œ RCNNë³´ë‹¤ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.
- ì¦‰ **YOLOv10n**ì˜ ì •ë°€ë„ì™€ ì•ˆì •ì„±ì´ ìš°ìˆ˜í•˜ë‹¤ëŠ” ì¦ê±°ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.
- ì†ë„ ë˜í•œ YOLOv10n ì´ ìƒëŒ€ì ìœ¼ë¡œ í¬ê²Œ ë¹ ë¥¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

# Language Model
## gpt ë˜ëŠ” gemini ë¥¼ ì´ìš©í•œ ë°ì´í„° ì…‹ ìƒì„±
- ì‚¬ìš© ë°ì´í„° ì…‹ : [gpt ìƒì„± ë°ì´í„°](data/text_data/output_text.json)
  - [gpt ìƒì„± ì½”ë“œ](code_data_gen/3_textdata_generating.ipynb)
  - í”„ë¡¬í”„íŒ… : 
    ```py
    def prompting(input_):
    return f"""
    ì‚¬ì§„ì— ëŒ€í•œ ëŒ“ê¸€ ì…ë ¥
    ì§ˆë¬¸ ê¸ˆì§€
    sns ì‚¬ì§„ ìš”ì†Œ : 'ë¶„ë…¸, ì—¬ì, ì¸ê°„ì˜ ì–¼êµ´, ê³µ, ì˜ë¥˜'
    sns ëŒ“ê¸€ : í™”ê°€ ë‚œ ë“¯í•œ í‘œì •ì´ë„¤! ğŸ€ ê³µì€ ë¬´ìŠ¨ ì¢…ë¥˜ì•¼? ì˜·ë„ ë©‹ì§€ë‹¤! ğŸ˜Š
    
    ì˜ˆì¸¡ í•œ ë¬¸ì¥
    sns ì‚¬ì§„ ìš”ì†Œ : {input_}
    sns ëŒ“ê¸€ : """
    ```
  - ì¶œë ¥ ì˜ˆì‹œ :
    ```py
    input_ = 'ê³µí¬, í—¤ë“œí°'
    output_ = 'ì•„ì°”í•œ ë¶„ìœ„ê¸°ë„¤ìš”! ğŸ§ ì–´ë–¤ ìŒì•… ë“£ê³  ê³„ì‹ ê°€ìš”? ê¶ê¸ˆí•´ìš”! ğŸ˜Š'
    ```

## Language Model : t5 (Text-to-Text Transfer Transformer)

- í•™ìŠµ ë°ì´í„° í˜•ì‹
  ```
  input_data = ['ìŠ¬í””, ë¶„ë…¸', ...]
  output_data = ['ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
  ```

#### ëª¨ë¸ í›ˆë ¨
  - transfer_0 : ê¸°ë³¸ê°’ìœ¼ë¡œ í›ˆë ¨
  - transfer_1 : 
    - ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ 0.1 -> 0.2
    - í›ˆë ¨ì‹œ ì¶”ê°€ ì¸ì
      ```
      learning_rate=5e-5,          # ê¸°ë³¸ê°’ì—ì„œ ì‹œì‘
      lr_scheduler_type="linear",  # ìŠ¤ì¼€ì¤„ëŸ¬
      warmup_steps=500,            # 500 ìŠ¤í… ë™ì•ˆ í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€
      weight_decay=0.01,           # l2 ì •ê·œí™” ê¸°ë²• ì¤‘ í•˜ë‚˜
      max_grad_norm=1.0,           # ê·¸ë¼ë””ì–¸íŠ¸ í´ë¦¬í•‘
      ```
    - transfer_1 : ë¡œì»¬ í™˜ê²½ ë° ê¸°ë³¸ base ëª¨ë¸ ì´ìš©
    - transfer_1_large_colab : colab í™˜ê²½ ë° large ëª¨ë¸ì´ìš©

  - t5 loss ê°’ ë¹„êµ ê·¸ë˜í”„
    - **LOSS(=Value)**
    ![ë¹„êµ ê·¸ë˜í”„](models/t5/val_loss_comparison.png)
  
  - ê²°ë¡  : ì„¸ ëª¨ë¸ì˜ í° ì°¨ì´ëŠ” ì—†ì–´ ë³´ì¸ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì´ì¤‘ íš¨ìœ¨ì¢‹ê³  loss ìµœì €ê°’ì´ ë‚®ì€ 0ë²ˆ(default) ë¡œ ì„ íƒ 
    - ê° ëª¨ë¸ë³„ íŠ¹ì§•
    ```text
    # loss ìµœì €
    - default = 0.1783
    - setting 1 = 0.1790
    - setting 1 with colab = 0.1745

    # ìš”êµ¬ vram
    - default = 6gb
    - setting 1 = 6gb
    - setting 1 with colab = 29gb
    ```




## Language Model : gpt2 (*Language Models are* **Unsupervised** *Multitask Learners*)
- ì¦‰ ì •ë‹µ ë¼ë²¨ì€ ì—†ë‹¤. (ë¹„ì§€ë„ í•™ìŠµ)
  - í•™ìŠµ ë°ì´í„° í˜•ì‹
    - ì²« ë²ˆì§¸ ë°©ì‹
      ```
      input_data = ['ìŠ¬í””, ë¶„ë…¸, ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
      ```
    - ë‘ ë²ˆì§¸ ë°©ì‹

      ë˜ëŠ” í…ìŠ¤íŠ¸ ë¡œ ì‹œí€€ìŠ¤ ë°ì´í„° ì•ˆì— ëª…ì‹œí•œë‹¤.
      ```
      input_data = ['ì…ë ¥ : ìŠ¬í””, ë¶„ë…¸ \n ì¶œë ¥ : ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
      ```
      ë˜í•œ ì˜ˆì¸¡ì‹œ ëª¨ë¸ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ```'ì…ë ¥ : ìŠ¬í””, ë¶„ë…¸ \n ì¶œë ¥ : ``` ì™€ ê°™ì´ ì…ë ¥í•˜ì—¬ ì¶œë ¥ê°’ì„ ì–»ì–´ì•¼í•¨

- skt ì˜ kogpt2 ì´ìš© : https://huggingface.co/skt/kogpt2-base-v2
  - ì‹œë„ 0
    ```py
    ë°°ì¹˜ : 16
    vram ìš”êµ¬ : ì•½ 6gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ì²« ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° : ê¸°ë³¸ ê°’
    ```
  - ì‹œë„ 1
    ```py
    ë°°ì¹˜ : 16
    vram ìš”êµ¬ : ì•½ 6gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ì²« ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
        learning_rate=5e-5,
        lr_scheduler_type="linear",
        warmup_steps=500,
        weight_decay=0.01[
        max_grad_norm=1.0,
    ```
  - ì‹œë„ 2
    ```py
    ë°°ì¹˜ : 16
    vram ìš”êµ¬ : ì•½ 6gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
      learning_rate=5e-5,
      lr_scheduler_type="linear",
      warmup_steps=500,
      weight_decay=0.01,
      max_grad_norm=1.0,
    ```


- open ai ì˜ gpt2-base ì´ìš© : https://huggingface.co/openai-community/gpt2
  - ì‹œë„ 0
    ```py
    ë°°ì¹˜ : 10
    vram ìš”êµ¬ : ì•½ 5gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° : ê¸°ë³¸ ê°’
    ```
  - ì‹œë„ 1
    ```py
    ë°°ì¹˜ : 10
    vram ìš”êµ¬ : ì•½ 5gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
        learning_rate=5e-5,
        lr_scheduler_type="linear",
        warmup_steps=500,
        weight_decay=0.01,
        max_grad_norm=1.0,
    ```
- ë¹„êµ ê·¸ë˜í”„
  - **Loss(=Value)**
  ![ë¹„êµ ê·¸ë˜í”„](models/gpt2//val_loss_comparison.png)

- ê° ëª¨ë¸ ìµœì € loss ë° ìŠ¤í…
  - kogpt2_0 loss : 0.293683
  - kogpt2_1 loss : 0.293336
  - kogpt2_2 loss : 0.72245
  - gpt2_base_0 loss : 0.716322
  - gpt2_base_1 loss : 0.925404
## ì–¸ì–´ ëª¨ë¸ ì„±ê³¼ ì§€í‘œ ë¹„êµ [BLEU-n](logs/LMmodel_BLEU.log), [METEOR](logs/LMmodel_METEOR.log), [ROUGE](logs/LMmodel_ROUGE.log)

### ğŸ¿[ì½”ë“œ](code_metric_check/_BLUE_Metero_ROUGE.ipynb)ğŸ¿

|ì„±ê³¼ ì§€í‘œ|t5-base|t5-large|gpt2|kogpt2|
|---|---|---|---|---|
|BLEU-1|0.6258|0.6127|0.4395|0.3900|
|BLEU-2|0.5360|0.5276|0.3592|0.2234|
|BLEU-3|0.4706|0.4651|0.3054|0.1338|
|BLEU-4|0.4105|0.4074|0.2580|0.0780|
|METEOR|0.2588|0.2599|0.1453|0.0248|
| **ROUGE-1** |              |              |              |              |
| ì¬í˜„ìœ¨     | 0.3537       | 0.3698       | 0.0444       | 0.2552       |
| ì •í™•ë„     | 0.3326       | 0.3318       | 0.0389       | 0.1929       |
| F1 ì ìˆ˜    | 0.3381       | 0.3448       | 0.0399       | 0.2162       |
| **ROUGE-2** |              |              |              |              |
| ì¬í˜„ìœ¨     | 0.1475       | 0.1594       | 0.0006       | 0.0871       |
| ì •í™•ë„     | 0.1372       | 0.1407       | 0.0009       | 0.0645       |
| F1 ì ìˆ˜    | 0.1398       | 0.1469       | 0.0007       | 0.0728       |
| **ROUGE-L** |              |              |              |              |
| ì¬í˜„ìœ¨     | 0.3314       | 0.3495       | 0.0420       | 0.2392       |
| ì •í™•ë„     | 0.3107       | 0.3140       | 0.0366       | 0.1808       |
| F1 ì ìˆ˜    | 0.3164       | 0.3262       | 0.0377       | 0.2026       |

### ê²°ë¡  GPT2 VS T5

- í˜„ í”„ë¡œì íŠ¸ì—ì„œ gpt2 ê³„ì—´ ëª¨ë¸ì¤‘ kogpt ë³´ë‹¤ gpt2 ê¸°ë³¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì˜ ê²°ê³¼ê°€ ë” ì¢‹ì•˜ë‹¤
- ë˜í•œ ëª¨ë“  í‰ê°€ ì§€í‘œì—ì„œ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì€ **T5-base** ëª¨ë¸ ì´ì—ˆë‹¤.

## ëª¨ë¸ ì—°ê²° íŒŒì´í”„ ë¼ì¸

### ğŸ¿[í”„ë¡ íŠ¸ ì—”ë“œ í”„ë¡œì íŠ¸ ë§í¬](https://github.com/crazy2894/project_3_service)ğŸ¿

ì½”ë“œ : [99_pipe_line.ipynb](code/99_pipe_line.ipynb)
ê° ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ë‚˜ì˜¨ ê²°ê³¼

<details>
  <summary>ì½”ë“œ ë³´ê¸°</summary>

```py
import torch
import numpy as np
import cv2
import io
import json
from PIL import Image

from ultralytics import YOLO
from ultralytics.models import YOLOv10
from transformers import T5TokenizerFast, T5ForConditionalGeneration, GPT2Tokenizer, GPT2LMHeadModel


test_image = cv2.imread('test.png')

# ì´ë¯¸ì§€ ëª¨ë¸
model_object_detect = YOLO('models/yolov8x-oiv7.pt')
model_face_emmotion = YOLOv10('models/yolov10n-face.pt')

# í…ìŠ¤íŠ¸ ëª¨ë¸
model_path_gpt2 = 'models/gpt2/models/'
model_gpt2 = GPT2LMHeadModel.from_pretrained(model_path_gpt2)
tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(model_path_gpt2 + '/tokenizer')

model_save_path_t5 = 'models/t5/model/'
model_t5 = T5ForConditionalGeneration.from_pretrained(model_save_path_t5)
tokenizer_t5 = T5TokenizerFast.from_pretrained(model_save_path_t5+ 'tokenizer')

# face ëª¨ë¸ ë¼ë²¨
emotion_mapping = {0 : 'ë¶„ë…¸', 1 : 'ìŠ¬í””', 2 : 'ê³µí¬', 3 : 'ê¸°ì¨'}

# oiv7 ëª¨ë¸ ë¼ë²¨ JSON íŒŒì¼ì—ì„œ ë”•ì…”ë„ˆë¦¬ ì½ê¸°
with open('models/oiv7_jabels.json', 'r') as file:
    oiv7_jabels = json.load(file)

def generate_text_gpt2(prompt, model, tokenizer, max_length=128, num_return_sequences=1):
    # ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”
    inputs = tokenizer.encode(prompt, return_tensors='pt')

    # ìƒì„± ì¸ìë¥¼ ì„¤ì •í•˜ì—¬ ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±
    outputs = model.generate(
        inputs,
        max_length=max_length,
        num_return_sequences=num_return_sequences,
        no_repeat_ngram_size=30,
        top_k=50,
        top_p=0.85,
        temperature=1.7,
        do_sample=True,
        early_stopping=True
    )

    # ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ë””ì½”ë”©
    generated_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]
    
    return generated_texts

def detect_objects(image: Image.Image):
    # PIL.Imageë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    np_image = np.array(image)
# --------------------------------- ì´ë¯¸ì§€ ì²˜ë¦¬ -------------------------------------------------------------
    # ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì§€
    results_object = model_object_detect(np_image)
    results_face_emotion = model_face_emmotion(np_image)

    # ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    od_image = results_object[0]
    fc_image = results_face_emotion[0]

    # numpy ë°°ì—´ì„ PIL.Imageë¡œ ë³€í™˜
    od_image_pil = Image.fromarray(od_image.plot())
    fc_image_pil = Image.fromarray(fc_image.plot())

    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ í˜•íƒœë¡œ ë³€í™˜
    output1 = io.BytesIO()
    output2 = io.BytesIO()

    od_image_pil.save(output1, format="PNG")
    fc_image_pil.save(output2, format="PNG")

# --------------------------------- í…ìŠ¤íŠ¸ ì²˜ë¦¬ -------------------------------------------------------------
    print(fc_image.boxes.cls)
    print(od_image.boxes.cls)

    label_fc = [oiv7_jabels[str(int(i))] for i in od_image .boxes.cls]
    label_od = [emotion_mapping[int(i)] for i in fc_image.boxes.cls]
    all_labels = label_fc + label_od
    exception_lst = ['ì¸ê°„ì˜ ì–¼êµ´','ì˜ë¥˜','ë‚¨ì','ì—¬ì','ì†Œë…„','ì†Œë…€'] # í…ìŠ¤íŠ¸ ì…ë ¥ ì œì™¸ ëª©ë¡

    text_intput_text = ''
    for i in all_labels:
        if i not in exception_lst:
            text_intput_text +=i + ','

    text_intput_text = text_intput_text[:-1]

    # t5
    # ì…ë ¥ í† í°í™”
    input_ids = tokenizer_t5.encode(text_intput_text, return_tensors='pt')

    # ëª¨ë¸ ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model_t5.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)

    # ì˜ˆì¸¡ ê²°ê³¼ ë””ì½”ë”©
    predicted_text = tokenizer_t5.decode(outputs[0], skip_special_tokens=True)

    t5_out = predicted_text

    # gpt2
    model_gpt2.eval()
    prompt = f"ì…ë ¥ê°’ : {text_intput_text} \nì¶œë ¥ê°’ :"
    generated_texts = generate_text_gpt2(prompt, model_gpt2, tokenizer_gpt2)

    return output1.getvalue(), output2.getvalue() ,t5_out, generated_texts

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # PIL.Imageë¡œ ë³€í™˜
    image = Image.fromarray(test_image)

    # ê°ì§€ í•¨ìˆ˜ í˜¸ì¶œ
    output1, output2 = detect_objects(image)

    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (í…ŒìŠ¤íŠ¸ìš©)
    with open('test/od_output.png', 'wb') as f:
        f.write(output1)
    
    with open('test/fc_output.png', 'wb') as f:
        f.write(output2)
```

</details>

#### íŒŒì´í”„ ë¼ì¸ í…ŒìŠ¤íŠ¸
<div style="display: flex; justify-content: space-between;">
    <img src="test.png" alt="PR Curve 1" style="width: 45%; height: auto;">
</div>

##### yolov10n-face + yolov8x-oiv7 + t5
ì…ë ¥ê°’: ê³µí¬,ëª¨ì | ì¶œë ¥ê°’: ë¬´ì„œìš´ ë¶„ìœ„ê¸°ê°€ ëŠê»´ì§€ë„¤ìš”! ğŸ˜± ì–´ë–¤ ìƒí™©ì¸ì§€ ê¶ê¸ˆí•´ìš”!

##### yolov10n-face + yolov8x-oiv7 + gpt2
ì…ë ¥ê°’: ê³µí¬,ëª¨ì | ì¶œë ¥ê°’ : ëª¨ì ì•ˆì—ì„œ ëŠê»´ì§€ëŠ” ê³µí¬ê°ì´ ëŠê»´ì§€ë„¤ìš”! ğŸ˜± ë¶„ìœ„ê¸°ê°€ ì •ë§ ê°•ë ¬í•´ìš”! ğŸ–¤ ï¿½

---
<details>
  <summary>íŒŒì¼ êµ¬ì¡°</summary>
  
  ### 2024-09-02
    code\1_ë°ì´í„°_í™•ì¸.ipynb  : fix
    requiremets.txt         : í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¡œ ìˆ˜ì •(ì—…ë°ì´íŠ¸ ì¤‘)
  ## íŒŒì¼ êµ¬ì¡°

  ### ğŸ“ code : ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡, ë°ì´í„° í™•ì¸ê´€ë ¨ ì½”ë“œ
  ```text
  1_ë°ì´í„° í™•ì¸.ipynb           # ë°ì´í„° í™•ì¸ ì½”ë“œ
  2_od_YOLO_finetunning.ipynb  # wassup ì–¼êµ´ ë°ì´í„° ì „ì´í•™ìŠµ
  2_od_YOLO_lvis.ipynb         # lvis ë°ì´í„°ì…‹ ì „ì´í•™ìŠµ
  3_lm_gpt2finetunning         # gpt2 ì „ì´í•™ìŠµ
  3_lm_t5                      # t5 ì „ì´í•™ìŠµ
  4_pipe_line                  # ì…ë ¥ë‹¨ë¶€í„° ìµœì¢… ì¶œë ¥ë‹¨ ê¹Œì§€ìœ¼ íŒŒì´í”„ë¼ì¸
  ```
  
  ### ëª¨ë¸ ì„¤ëª…
  ```text
  yolov8m-oiv7.pt              # ê°ì²´ ê²€ì¶œ ëª¨ë¸ ì¤‘ê°„ ì‚¬ì´ì¦ˆ
  yolov8x-oiv7.pt              # ê°ì²´ ê²€ì¶œ ëª¨ë¸ ë¼ì§€ ì‚¬ì´ì¦ˆ
  yolov10n-face.pt             # wassup datasetìœ¼ë¡œ ì „ì´í•™ìŠµí•œ ëª¨ë¸
  ```
  
  ### ğŸ“ code_data_gen : api ë¥¼ ì´ìš©í•œ ì½”ë“œ
  ```text
  1_chat_gpt_translate.ipynb   # í…ìŠ¤íŠ¸ ë²ˆì—­ ëª¨ë¸ (oiv7 ì˜ ì •ë‹µ ë¼ë²¨ ë²ˆì—­ì„ ìœ„í•œ ì½”ë“œ)
  2_img_pred_and_gen.ipynb     # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í›„ ì¶œë ¥ ê°’ì„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œ
  3_textdata_generating.ipynb  # text to text ë¡œ ëŒ“ê¸€ ë°ì´í„° ìƒì„± ì½”ë“œ
  ```
</details>

# ë§í¬ : [ì§„í–‰ê³¼ì • í‘œ](https://docs.google.com/spreadsheets/d/1OklwBcfJiqlj7JJHE1Pez9jpgLctun0BPKrBD4HW2A0/edit?gid=1967477975#gid=1967477975) , [ê¸°íšì•ˆ](https://docs.google.com/presentation/d/1HKMJk6zLfsEqedcVdcQipHY8V8snd6oP2ajS9FDFgKI/edit#slide=id.p), 