# SNS ì‚¬ì§„ ë¶„ì„ ëŒ“ê¸€ ë° í”¼ë“œë°± í”„ë¡œì íŠ¸

- íŒŒì´ì¬ ë²„ì „
    ```bash
    conda create -n project_3 python==3.11
    ```
- íŒ¨í‚¤ì§€ ì„¤ì¹˜
    ```bash
    git clone https://github.com/crazy2894/project_3_git.git
    cd project_3_git
    pip install -r requiremets.txt
    ```

**ëª¨ë“  ëª¨ë¸ì—ì„œ earlystopping ,patient = 10 ì´ìš©**

## Oject Dection + classification ëª¨ë¸
### ì‚¬ìš© ë°ì´í„° ì…‹ : ì•ˆë©´ ë°ì´í„°

### YOLOv10
#### [**ë°ì´í„° ì „ì²˜ë¦¬**](code\1_2ë°ì´í„°_ì „ì²˜ë¦¬_yolo.ipynb)
  ```py
  json í˜•ì‹ì˜ íŒŒì¼ì„ íŒŒì¼ í•˜ë‚˜ í•˜ë‚˜ ë¶„ë¦¬í•˜ì—¬ ë™ì¼ í´ë”ì— ë™ì¼ ì´ë¦„ìœ¼ë¡œ txt íŒŒì¼ë¡œ ì €ì¥
  ê¸°ë³¸ì ì¸ ì ˆëŒ€ ìœ„ì¹˜ì˜ í˜•ì‹ì„ yolo ì—ì„œ ìš”êµ¬í•˜ëŠ” ìƒëŒ€ ì¤‘ì‹¬ ìœ„ì¹˜ì™€ ìƒëŒ€ ë°•ìŠ¤ í¬ê¸°ë¡œ ì§€ì • í•˜ì˜€ìŒ
  ```
  - ì „ì²˜ë¦¬ ì½”ë“œ í•¨ìˆ˜ ì •ì˜
    ```py
    def convert_bbox_to_yolo_format(image_size, bbox):
      """
      ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
      :param image_size: (width, height) ì´ë¯¸ì§€ í¬ê¸°
      :param bbox: {'minX': float, 'minY': float, 'maxX': float, 'maxY': float} ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
      :return: (x_center, y_center, width, height) YOLO í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤
      """
      dw = 1.0 / image_size[0]
      dh = 1.0 / image_size[1]
      x_center = (bbox['minX'] + bbox['maxX']) / 2.0
      y_center = (bbox['minY'] + bbox['maxY']) / 2.0
      width = bbox['maxX'] - bbox['minX']
      height = bbox['maxY'] - bbox['minY']

      # YOLO í˜•ì‹ì— ë§ê²Œ ì¢Œí‘œë¥¼ ì •ê·œí™”
      x_center = x_center * dw
      y_center = y_center * dh
      width = width * dw
      height = height * dh

      return (x_center, y_center, width, height)
    ```
  - ì „ì²˜ë¦¬ í›„ íŒŒì¼ ì €ì¥ í•¨ìˆ˜ ì •ì˜
    ```py
    def save_annotations(json_data, output_dir, image_size):
    """
    ì´ë¯¸ì§€ë¥¼ yolo ì— ë§ê²Œ
    txt íŒŒì¼ ìƒì„± (ìœ„ì˜ í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì™€ í˜•ì‹ ë³€í™˜ í›„ ì €ì¥.)
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for item in json_data:
        image_file = item['filename']
        image_name, _ = os.path.splitext(image_file)
        txt_file_path = os.path.join(output_dir, f"{image_name}.txt")
        
        with open(txt_file_path, 'w') as f:
            # Iterate over annotations (A, B, C)
            annot = item.get('annot_A')
            print(annot)
            if annot:
                bbox = annot['boxes']
                face_exp = item['faceExp_uploader']
                class_id = class_to_id.get(face_exp, -1)
                if class_id == -1:
                    class_id = 3
                print(class_id)
                if class_id != -1:
                    yolo_bbox = convert_bbox_to_yolo_format(image_size, bbox)
                    print(yolo_bbox)
                    f.write(f"{class_id} {' '.join(map(str, yolo_bbox))}\n")
                    print(f"{class_id} {' '.join(map(str, yolo_bbox))}\n")
    ```
  - yaml íŒŒì¼ ìƒì„±
    ```text
    train: ./data/yolo_data/train
    val: ./data/yolo_data/val
    nc: 4
    names: ['anger', 'sad', 'panic', 'happy']
    ```
#### ëª¨ë¸ í›ˆë ¨

[í›ˆë ¨ ì½”ë“œ](code/2_YOLO_1_transfer_1.ipynb)
```py
from ultralytics.models import YOLOv10

model_for_trian = YOLOv10("models/yolov10/pt_models/yolov10n.pt")
model_for_trian.train(data="wassup_data.yaml", epochs=10000, imgsz=512, patience=10)
```
- ì†Œìš” ì‹œê°„ : gpu 3060 - 63 epochs completed in 6.935 hours.

## Language Model

### gpt ë˜ëŠ” gemini ë¥¼ ì´ìš©í•œ ë°ì´í„° ì…‹ ìƒì„±
- ì‚¬ìš© ë°ì´í„° ì…‹ : [gpt ìƒì„± ë°ì´í„°](data/text_data/output_text.json)
  - [gpt ìƒì„± ì½”ë“œ](code_data_gen/3_textdata_generating.ipynb)
  - í”„ë¡¬í”„íŒ… : 
    ```py
    def prompting(input_):
    return f"""
    ì‚¬ì§„ì— ëŒ€í•œ ëŒ“ê¸€ ì…ë ¥
    ì§ˆë¬¸ ê¸ˆì§€
    sns ì‚¬ì§„ ìš”ì†Œ : 'ë¶„ë…¸, ì—¬ì, ì¸ê°„ì˜ ì–¼êµ´, ê³µ, ì˜ë¥˜'
    sns ëŒ“ê¸€ : í™”ê°€ ë‚œ ë“¯í•œ í‘œì •ì´ë„¤! ğŸ€ ê³µì€ ë¬´ìŠ¨ ì¢…ë¥˜ì•¼? ì˜·ë„ ë©‹ì§€ë‹¤! ğŸ˜Š
    
    ì˜ˆì¸¡ í•œ ë¬¸ì¥
    sns ì‚¬ì§„ ìš”ì†Œ : {input_}
    sns ëŒ“ê¸€ : """
    ```
  - ì¶œë ¥ ì˜ˆì‹œ :
    ```py
    input_ = 'ê³µí¬, í—¤ë“œí°'
    output_ = 'ì•„ì°”í•œ ë¶„ìœ„ê¸°ë„¤ìš”! ğŸ§ ì–´ë–¤ ìŒì•… ë“£ê³  ê³„ì‹ ê°€ìš”? ê¶ê¸ˆí•´ìš”! ğŸ˜Š'
    ```

### t5 (Text-to-Text Transfer Transformer)

- í•™ìŠµ ë°ì´í„° í˜•ì‹
  ```
  input_data = ['ìŠ¬í””, ë¶„ë…¸', ...]
  output_data = ['ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
  ```

#### ëª¨ë¸ í›ˆë ¨
  - transfer_0 : ê¸°ë³¸ê°’ìœ¼ë¡œ í›ˆë ¨
  - transfer_1 : 
    - ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ 0.1 -> 0.2
    - í›ˆë ¨ì‹œ ì¶”ê°€ ì¸ì
      ```
      learning_rate=5e-5,          # ê¸°ë³¸ê°’ì—ì„œ ì‹œì‘
      lr_scheduler_type="linear",  # ìŠ¤ì¼€ì¤„ëŸ¬
      warmup_steps=500,            # 500 ìŠ¤í… ë™ì•ˆ í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€
      weight_decay=0.01,           # l2 ì •ê·œí™” ê¸°ë²• ì¤‘ í•˜ë‚˜
      max_grad_norm=1.0,           # ê·¸ë¼ë””ì–¸íŠ¸ í´ë¦¬í•‘
      ```
    - transfer_1 : ë¡œì»¬ í™˜ê²½ ë° ê¸°ë³¸ base ëª¨ë¸ ì´ìš©
    - transfer_1_large_colab : colab í™˜ê²½ ë° large ëª¨ë¸ì´ìš©

  - t5 ë¹„êµ ê·¸ë˜í”„
    ![ë¹„êµ ê·¸ë˜í”„](models/t5/val_loss_comparison.png)
  
  - ê²°ë¡  : ì„¸ ëª¨ë¸ì˜ í° ì°¨ì´ëŠ” ì—†ì–´ ë³´ì¸ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì´ì¤‘ íš¨ìœ¨ì¢‹ê³  loss ìµœì €ê°’ì´ ë‚®ì€ 0ë²ˆ(default) ë¡œ ì„ íƒ 
    - ê° ëª¨ë¸ë³„ íŠ¹ì§•
    ```text
    # loss ìµœì €
    - default = 0.1783
    - setting 1 = 0.1790
    - setting 1 with colab = 0.1745

    # ìš”êµ¬ vram
    - default = 6gb
    - setting 1 = 6gb
    - setting 1 with colab = 29gb
    ```




### gpt2 (*Language Models are* **Unsupervised** *Multitask Learners*)
- ì¦‰ ì •ë‹µ ë¼ë²¨ì€ ì—†ë‹¤. (ë¹„ì§€ë„ í•™ìŠµ)
  - í•™ìŠµ ë°ì´í„° í˜•ì‹
    - ì²« ë²ˆì§¸ ë°©ì‹
      ```
      input_data = ['ìŠ¬í””, ë¶„ë…¸, ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
      ```
    - ë‘ ë²ˆì§¸ ë°©ì‹

      ë˜ëŠ” í…ìŠ¤íŠ¸ ë¡œ ì‹œí€€ìŠ¤ ë°ì´í„° ì•ˆì— ëª…ì‹œí•œë‹¤.
      ```
      input_data = ['ì…ë ¥ : ìŠ¬í””, ë¶„ë…¸ \n ì¶œë ¥ : ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
      ```
      ë˜í•œ ì˜ˆì¸¡ì‹œ ëª¨ë¸ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ```'ì…ë ¥ : ìŠ¬í””, ë¶„ë…¸ \n ì¶œë ¥ : ``` ì™€ ê°™ì´ ì…ë ¥í•˜ì—¬ ì¶œë ¥ê°’ì„ ì–»ì–´ì•¼í•¨

#### [kogpt2](https://huggingface.co/skt/kogpt2-base-v2)
skt ì˜ kogpt2 ì´ìš© : https://huggingface.co/skt/kogpt2-base-v2
- ì‹œë„ 0
  ```py
  ë°°ì¹˜ : 16
  vram ìš”êµ¬ : ì•½ 6gb
  ì…ë ¥ ë°ì´í„° í˜•ì‹ : ì²« ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
  í•˜ì´í¼ íŒŒë¼ë¯¸í„° : ê¸°ë³¸ ê°’
  ```
- ì‹œë„ 1
  ```py
  ë°°ì¹˜ : 16
  vram ìš”êµ¬ : ì•½ 6gb
  ì…ë ¥ ë°ì´í„° í˜•ì‹ : ì²« ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
  í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
      learning_rate=5e-5,
      lr_scheduler_type="linear",
      warmup_steps=500,
      weight_decay=0.01[
      max_grad_norm=1.0,
  ```
- ì‹œë„ 2
  ```py
  ë°°ì¹˜ : 16
  vram ìš”êµ¬ : ì•½ 6gb
  ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
  í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
    learning_rate=5e-5,
    lr_scheduler_type="linear",
    warmup_steps=500,
    weight_decay=0.01[
    max_grad_norm=1.0,
  ```

#### [gpt2-base](https://huggingface.co/openai-community/gpt2)
open ai ì˜ gpt2-base ì´ìš© : https://huggingface.co/openai-community/gpt2
- ì‹œë„ 0
  ```py
  ë°°ì¹˜ : 10
  vram ìš”êµ¬ : ì•½ 5gb
  ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
  í•˜ì´í¼ íŒŒë¼ë¯¸í„° : ê¸°ë³¸ ê°’
  ```
- ì‹œë„ 1
  ```py
  ë°°ì¹˜ : 10
  vram ìš”êµ¬ : ì•½ 5gb
  ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
  í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
      learning_rate=5e-5,
      lr_scheduler_type="linear",
      warmup_steps=500,
      weight_decay=0.01[
      max_grad_norm=1.0,
  ```
- ë¹„êµ ê·¸ë˜í”„
  ![ë¹„êµ ê·¸ë˜í”„](models/gpt2//val_loss_comparison.png)

- ê° ëª¨ë¸ ìµœì € loss ë° ìŠ¤í…
    
    kogpt2_0
    Step     Value
    7000  0.293683
    
    kogpt2_1
    Step     Value
    6000  0.293336
    
    kogpt2_2
    Step    Value
    313  0.72245
    
    gpt2_base_0
    Step     Value
    1565  0.716322
    
    gpt2_base_1
    Step     Value
    2000  0.925404
    

#### ê²°ë¡ 

í˜„ í”„ë¡œì íŠ¸ì—ì„œëŠ” kogpt ë³´ë‹¤ gpt2 ê¸°ë³¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì˜ ê²°ê³¼ê°€ ë” ì¢‹ì•˜ë‹¤
ì¢€ ë” ë§ì€ í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì€ ì‹œê°„ ê´€ê³„ìƒ ìƒëµ í•˜ì˜€ë‹¤

ì¶”í›„ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ” ê³¼ì •ì´ í•„ìš” í•  ê²ƒì´ë‹¤ (grid search or randomized search)

<details>
  <summary>ì‚­ì œ ë‚´ìš©</summary>
  
  ### 2024-09-02
    code\1_ë°ì´í„°_í™•ì¸.ipynb  : fix
    requiremets.txt         : í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¡œ ìˆ˜ì •(ì—…ë°ì´íŠ¸ ì¤‘)
  ## íŒŒì¼ êµ¬ì¡°

  ### ğŸ“ code : ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡, ë°ì´í„° í™•ì¸ê´€ë ¨ ì½”ë“œ
  ```text
  1_ë°ì´í„° í™•ì¸.ipynb           # ë°ì´í„° í™•ì¸ ì½”ë“œ
  2_od_YOLO_finetunning.ipynb  # wassup ì–¼êµ´ ë°ì´í„° ì „ì´í•™ìŠµ
  2_od_YOLO_lvis.ipynb         # lvis ë°ì´í„°ì…‹ ì „ì´í•™ìŠµ
  3_lm_gpt2finetunning         # gpt2 ì „ì´í•™ìŠµ
  3_lm_t5                      # t5 ì „ì´í•™ìŠµ
  4_pipe_line                  # ì…ë ¥ë‹¨ë¶€í„° ìµœì¢… ì¶œë ¥ë‹¨ ê¹Œì§€ìœ¼ íŒŒì´í”„ë¼ì¸
  ```
  
  ### ëª¨ë¸ ì„¤ëª…
  ```text
  yolov8m-oiv7.pt              # ê°ì²´ ê²€ì¶œ ëª¨ë¸ ì¤‘ê°„ ì‚¬ì´ì¦ˆ
  yolov8x-oiv7.pt              # ê°ì²´ ê²€ì¶œ ëª¨ë¸ ë¼ì§€ ì‚¬ì´ì¦ˆ
  yolov10n-face.pt             # wassup datasetìœ¼ë¡œ ì „ì´í•™ìŠµí•œ ëª¨ë¸
  ```
  
  ### ğŸ“ code_data_gen : api ë¥¼ ì´ìš©í•œ ì½”ë“œ
  ```text
  1_chat_gpt_translate.ipynb   # í…ìŠ¤íŠ¸ ë²ˆì—­ ëª¨ë¸ (oiv7 ì˜ ì •ë‹µ ë¼ë²¨ ë²ˆì—­ì„ ìœ„í•œ ì½”ë“œ)
  2_img_pred_and_gen.ipynb     # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í›„ ì¶œë ¥ ê°’ì„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œ
  3_textdata_generating.ipynb  # text to text ë¡œ ëŒ“ê¸€ ë°ì´í„° ìƒì„± ì½”ë“œ
  ```
</details>

# ë§í¬ : [ì§„í–‰ê³¼ì • í‘œ](https://docs.google.com/spreadsheets/d/1OklwBcfJiqlj7JJHE1Pez9jpgLctun0BPKrBD4HW2A0/edit?gid=1967477975#gid=1967477975) , [ê¸°íšì•ˆ](https://docs.google.com/presentation/d/1HKMJk6zLfsEqedcVdcQipHY8V8snd6oP2ajS9FDFgKI/edit#slide=id.p), 