# SNS ì‚¬ì§„ ë¶„ì„ ëŒ“ê¸€ ë° í”¼ë“œë°± í”„ë¡œì íŠ¸

- íŒŒì´ì¬ ë²„ì „
    ```bash
    conda create -n project_3 python==3.11
    ```
- íŒ¨í‚¤ì§€ ì„¤ì¹˜
    ```bash
    git clone https://github.com/crazy2894/project_3_git.git
    cd project_3_git
    pip install -r requiremets.txt
    ```

#### ê³µí†µ ì‚¬í•­
**ëª¨ë“  ëª¨ë¸ì—ì„œ earlystopping ,patient = 10 ì´ìš©**<br>
**(Faster R-CNN ì œì™¸ : ì»¤ìŠ¤í…€ ealrystop ìš”êµ¬)**

## to do list ë° ckeck list
```
- ê³µì‹ tta ì„±ëŠ¥ì§€í‘œ í™•ì¸ í›„ ì ìš© ê°€ëŠ¥ì‹œ ì ìš©ì‹œ ë¹„êµ
- ê°ê° ì™œ ì´ ëª¨ë¸ì„ ì¼ëŠ”ì§€ ì •í™•í•œ ì‚¬í•­ ê¸°ì¬
- ì§€í‘œ ë° ì„±ê³¼ ë˜í•œ ì •í™•íˆ ê³µì‹ tta ê¸°ì¤€ í™•ì¸í›„ ë¹„êµ ì§€í‘œë¡œ ì§€ì •
- 15 ë¶„ ë°œí‘œ ì‹œê°„ ë§ì¶”ê¸°
```

<span style="color: #FF5733;">ì´ í…ìŠ¤íŠ¸ëŠ” ì§€ì •ëœ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.</span>

# Oject Detection + classification ëª¨ë¸
### ì‚¬ìš© ëª¨ë¸ : 
#### ì˜¤ë¸Œì íŠ¸ ë””í…ì…˜ ëª¨ë¸
- detectron2 : https://github.com/facebookresearch/detectron2
  - faster_rcnn_R_50_FPN_3x : ì–¼êµ´ ë°ì´í„° ê°ì • ë¶„ë¥˜ **ì „ì´ í•™ìŠµ**
    ```
    **ì „ì´ í•™ìŠµ**
    ë†’ì€ ì •í™•ë„, ê°ì • ë¶„ë¥˜ì— ì´ìš©, Yolo ì™€ ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•´ ì‚¬ìš© ë¨
    ```

- ultralytics : https://www.ultralytics.com/ko
  - [yolov10n](https://github.com/THU-MIG/yolov10) : ì–¼êµ´ ë°ì´í„° ê°ì • ë¶„ë¥˜ **ì „ì´ í•™ìŠµ**
    ```
    **ì „ì´ í•™ìŠµ**
    ë¹ ë¥¸ ì¶”ë¡  ë° ì‹¤ì‹œê°„ ê°ì •ë¶„ë¥˜ ê°€ëŠ¥, ì ì€ ë¹„ìš©ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ëƒ„, SOTA ëª¨ë¸
    ```
  - [yolov8x-oiv7](https://docs.ultralytics.com/ko/datasets/detect/open-images-v7/#open-images-v7-pretrained-models) 
    ```
    **ì‚¬ì „ í•™ìŠµ ëª¨ë¸**
    ê°ì²´ ê²€ì¶œ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì´ìš©
    ```

#### ì–¸ì–´ ëª¨ë¸(Transformer based) :
- T5 **ì „ì´ í•™ìŠµ**
  - T5-base : https://huggingface.co/paust/pko-t5-base
  - T5-large : https://huggingface.co/paust/pko-t5-large
  ```
  **ì „ì´ í•™ìŠµ**
  ê³µí†µ : ìƒëŒ€ì ìœ¼ë¡œ LLM ë³´ë‹¤ ì‘ì€ ëª¨ë¸ì„ì—ë„ ì •í•´ì§„ í…ŒìŠ¤í¬ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì„
  ë¹„êµë¥¼ ìœ„í•´ base ëª¨ë¸ê³¼ large ëª¨ë¸ ì´ìš©
  ```
- gpt2 **ì „ì´ í•™ìŠµ**
  - kogpt2 : https://huggingface.co/skt/kogpt2-base-v2
  - gpt2 : https://huggingface.co/openai-community/gpt2
  ```
  **ì „ì´ í•™ìŠµ**
  ê³µí†µ : íŠ¸ëœìŠ¤ ëª¨ë¸ ê¸°ë°˜ì˜ ëª¨ë¸ë¡œ, ììœ ë¡œìš´ í…ìŠ¤íŠ¸ ìƒì„± ëŠ¥ë ¥ì´ ë›°ì–´ë‚¨ llmë“¤ì˜ ì´ˆê¸°ëª¨ë¸.
  kogpt2 : í•œêµ­ì–´ì— íŠ¹í™”ëœ gpt2 ëª¨ë¸. í•œêµ­ì–´ì— ëŒ€í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ìƒì„± ì˜ˆìƒ.
  gpt2 : í•œêµ­ì–´ ëª¨ë¸ê³¼ ë¹„êµ.
  ```
### ì‚¬ìš© ë°ì´í„° ì…‹ :
- ì´ë¯¸ì§€ ë°ì´í„° ì…‹: wassup ì•ˆë©´ ë°ì´í„°
  - yolo í˜•ì‹ìœ¼ë¡œ annotation ë³€í™˜ : [ì½”ë“œ](code/1_2ë°ì´í„°_ì „ì²˜ë¦¬_yolo.ipynb)
  - yolo í˜•ì‹ì—ì„œ COCOë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜ : [ì½”ë“œ](code/1_3ë°ì´í„°_ì „ì²˜ë¦¬_ssd,rcnn.ipynb)

- í…ìŠ¤íŠ¸ ë°ì´í„° ì…‹ : ì¶œë ¥ëœ ì´ë¯¸ì§€ ë¼ë²¨[ê°ì • ë¶„ë¥˜ ë° ,yolov8x-oiv7 ì¶œë ¥] ì„ ì´ìš©í•˜ì—¬ ìƒì„± : [ì½”ë“œ](code_data_gen/3_textdata_generating.ipynb)
  - gemini ë° gpt api ì´ìš© ë° í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
    ```py
    def prompting(input_):
      return f"""
    ì‚¬ì§„ì— ëŒ€í•œ ëŒ“ê¸€ ì…ë ¥
    ì§ˆë¬¸ ê¸ˆì§€
    sns ì‚¬ì§„ ìš”ì†Œ : 'ë¶„ë…¸, ì—¬ì, ì¸ê°„ì˜ ì–¼êµ´, ê³µ, ì˜ë¥˜'
    sns ëŒ“ê¸€ : í™”ê°€ ë‚œ ë“¯í•œ í‘œì •ì´ë„¤! ğŸ€ ê³µì€ ë¬´ìŠ¨ ì¢…ë¥˜ì•¼? ì˜·ë„ ë©‹ì§€ë‹¤! ğŸ˜Š
    
    ì˜ˆì¸¡ í•œ ë¬¸ì¥
    sns ì‚¬ì§„ ìš”ì†Œ : {input_}
    sns ëŒ“ê¸€ : """
    ```

## Obect Detection 1 : Faster R-CNN
### detectron2 from facebook
- ê¸°ë³¸ì ìœ¼ë¡œ detectron2 ì˜ faster-rcnn ì„ ì´ìš©í•¨
  ```bash
  git clone https://github.com/facebookresearch/detectron2.git
  python -m pip install -e detectron2
  ```

### ê¸°ë³¸ ì •ë³´
```
- ì†Œìš” ì‹œê°„ : ì§„í–‰ì¤‘ ... (ê³¼ì í•© ì „ê¹Œì§€ì˜ ì†Œìš” ì‹œê°„)
- í•„ìš” ë¦¬ì†ŒìŠ¤ : ì•½ 4GBì˜ ë©”ëª¨ë¦¬
```

###  [**ë°ì´í„° ì „ì²˜ë¦¬**](code/1_3ë°ì´í„°_ì „ì²˜ë¦¬_ssd,rcnn.ipynb)
  ```py
  # ê¸°ë³¸ ì ìœ¼ë¡œ COCO ë°ì´í„° ì…‹ê³¼ë™ì¼í•œ í˜•ì‹
  # ì‚¬ì§„ì˜ width ì™€ heightë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ ì˜¬ë°”ë¥´ê²Œ ë¶ˆëŸ¬ì˜¤ì§€ ì•ŠìŒ
    # => exif ë¥¼ ì´ìš©í•˜ì—¬ íšŒì „ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì ìš©í•¨
    def read_image_size_from_exif(image_path):
      with Image.open(image_path) as img:
          # EXIF ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
          exif = img._getexif()

          # EXIF ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ í¬ê¸° ë°˜í™˜
          if exif is None:
              return img.size

          # Orientation íƒœê·¸ ê°€ì ¸ì˜¤ê¸°
          orientation_key = [key for key, val in TAGS.items() if val ==   'Orientation'][0]
          orientation = exif.get(orientation_key, 1)  # EXIFì—ì„œ Orientation  ê°’ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 1ì„ ì‚¬ìš©

          # Orientationì— ë”°ë¼ ì´ë¯¸ì§€ íšŒì „
          if orientation == 3:
              img = img.rotate(180, expand=True)
          elif orientation == 6:
              img = img.rotate(270, expand=True)
          elif orientation == 8:
              img = img.rotate(90, expand=True)

          # íšŒì „ëœ í›„ì˜ ì´ë¯¸ì§€ í¬ê¸° ë°˜í™˜
          return img.size
  # ì´í›„ YOLO í˜•ì‹ì˜ annotation => COCO í˜•ì‹ì˜ annotation
  ```
###  [**í›ˆë ¨ ì½”ë“œ**](code/2_RCNN_0_transfer.ipynb)
  - ì„¤ì • í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì„¤ëª…
    ```py
    cfg = get_cfg()

    # ì–´ë–¤ ë°±ë³¸ ëª¨ë¸ì„ ì´ìš©í• ì§€ ì„¤ì • (í˜„ì œ ì„¤ì •ê°’ : resnet-50) ì¶”ê°€ ë°±ë³¸ í™•ì¸
    #https://github.com/facebookresearch/detectron2/tree/main/configs/COCO-Detection
    cfg.merge_from_file("detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")
    # ë°ì´í„° ì…‹ ì„¤ì •
    cfg.DATASETS.TRAIN = ("face_data_set",)
    cfg.DATASETS.TEST = ("face_data_set_valid",)

    # ë°ì´í„° ë¡œë”© ì‚¬ìš© í”„ë¡œì„¸ì„œ ìˆ˜
    cfg.DATALOADER.NUM_WORKERS = 2

    # ì´ˆê¸° ê°€ì¤‘ì¹˜ COCO ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ í•™ìŠµëœ Mask R-CNN ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©
    cfg.MODEL.WEIGHTS = "detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl"
    
    # ê° ë°°ì¹˜(batch)ë‹¹ ì´ë¯¸ì§€ ìˆ˜ë¥¼ ì§€ì •
    cfg.SOLVER.IMS_PER_BATCH = 16

    # í•™ìŠµì˜ ê¸°ë³¸ í•™ìŠµë¥ (learning rate)ì„ ì§€ì •
    cfg.SOLVER.BASE_LR = 0.001
    # ìµœëŒ€ í•™ìŠµ ë°˜ë³µ íšŸìˆ˜(iterations)ë¥¼ ì§€ì •
    cfg.SOLVER.MAX_ITER = 1000

    # ì‚¬ì§„ ë¦¬ ì‚¬ì´ì§• (yolo ì™€ ê°™ì€ ë¹„êµë¥¼ ìœ„í•´)
    cfg.INPUT.MIN_SIZE_TRAIN = 512
    cfg.INPUT.MAX_SIZE_TRAIN = 512
    cfg.INPUT.MIN_SIZE_TEST = 512
    cfg.INPUT.MAX_SIZE_TEST = 512

    # ë°ì´í„° ì¦ê°•
    cfg.INPUT.RANDOM_FLIP = "horizontal"
    cfg.INPUT.RANDOM_ROTATION = 30
    cfg.INPUT.CROP = CN({"ENABLED": True, "TYPE": "relative_range", "SIZE": [0.8, 0.8]})

    # Region Of Interest ë°°ì¹˜ í¬ê¸° ì§€ì • ë° í´ë˜ìŠ¤ ê°œìˆ˜ ì§€ì •
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4

    # ì¶œë ¥
    cfg.OUTPUT_DIR = "./models/faster_rcnn_R_50_FPN_3x"

    # í‰ê°€ / iter
    cfg.TEST.EVAL_PERIOD = 1000

    # ì €ì¥ / iter
    cfg.SOLVER.CHECKPOINT_PERIOD = 500

    # ì›œì—… iter ì •í•˜ê³  ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë¦„ ì •í•˜ê¸°
    cfg.SOLVER.LR_SCHEDULER_NAME = "WarmupCosineLR"
    cfg.SOLVER.WARMUP_ITERS = 500
    ```

## YOLOv10
### ê¸°ë³¸ ì •ë³´
```
- ì†Œìš” ì‹œê°„ : ì•½ 7 ì‹œê°„ (ì´ 63 ì—í¬í¬) - early stopping ê¹Œì§€ì˜ ì‹œê°„
- early stopping petient : 10
- í•„ìš” ë¦¬ì†ŒìŠ¤ : ì•½ 4GBì˜ ë©”ëª¨ë¦¬
```

### [**ë°ì´í„° ì „ì²˜ë¦¬**](code/1_2ë°ì´í„°_ì „ì²˜ë¦¬_yolo.ipynb)
  ```py
  json í˜•ì‹ì˜ íŒŒì¼ì„ íŒŒì¼ í•˜ë‚˜ í•˜ë‚˜ ë¶„ë¦¬í•˜ì—¬ ë™ì¼ í´ë”ì— ë™ì¼ ì´ë¦„ìœ¼ë¡œ txt íŒŒì¼ë¡œ ì €ì¥
  ê¸°ë³¸ì ì¸ ì ˆëŒ€ ìœ„ì¹˜ì˜ í˜•ì‹ì„ yolo ì—ì„œ ìš”êµ¬í•˜ëŠ” ìƒëŒ€ ì¤‘ì‹¬ ìœ„ì¹˜ì™€ ìƒëŒ€ ë°•ìŠ¤ í¬ê¸°ë¡œ ì§€ì • í•˜ì˜€ìŒ
  ```
  - ì „ì²˜ë¦¬ ì½”ë“œ í•¨ìˆ˜ ì •ì˜
    ```py
    def convert_bbox_to_yolo_format(image_size, bbox):
      """
      ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
      :param image_size: (width, height) ì´ë¯¸ì§€ í¬ê¸°
      :param bbox: {'minX': float, 'minY': float, 'maxX': float, 'maxY': float} ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
      :return: (x_center, y_center, width, height) YOLO í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤
      """
      dw = 1.0 / image_size[0]
      dh = 1.0 / image_size[1]
      x_center = (bbox['minX'] + bbox['maxX']) / 2.0
      y_center = (bbox['minY'] + bbox['maxY']) / 2.0
      width = bbox['maxX'] - bbox['minX']
      height = bbox['maxY'] - bbox['minY']

      # YOLO í˜•ì‹ì— ë§ê²Œ ì¢Œí‘œë¥¼ ì •ê·œí™”
      x_center = x_center * dw
      y_center = y_center * dh
      width = width * dw
      height = height * dh

      return (x_center, y_center, width, height)
    ```
  - ì „ì²˜ë¦¬ í›„ íŒŒì¼ ì €ì¥ í•¨ìˆ˜ ì •ì˜
    ```py
    def save_annotations(json_data, output_dir, image_size):
    """
    ì´ë¯¸ì§€ë¥¼ yolo ì— ë§ê²Œ
    txt íŒŒì¼ ìƒì„± (ìœ„ì˜ í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ì™€ í˜•ì‹ ë³€í™˜ í›„ ì €ì¥.)
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for item in json_data:
        image_file = item['filename']
        image_name, _ = os.path.splitext(image_file)
        txt_file_path = os.path.join(output_dir, f"{image_name}.txt")
        
        with open(txt_file_path, 'w') as f:
            # Iterate over annotations (A, B, C)
            annot = item.get('annot_A')
            print(annot)
            if annot:
                bbox = annot['boxes']
                face_exp = item['faceExp_uploader']
                class_id = class_to_id.get(face_exp, -1)
                if class_id == -1:
                    class_id = 3
                print(class_id)
                if class_id != -1:
                    yolo_bbox = convert_bbox_to_yolo_format(image_size, bbox)
                    print(yolo_bbox)
                    f.write(f"{class_id} {' '.join(map(str, yolo_bbox))}\n")
                    print(f"{class_id} {' '.join(map(str, yolo_bbox))}\n")
    ```
  - yaml íŒŒì¼ ìƒì„±
    ```text
    train: ./data/yolo_data/train
    val: ./data/yolo_data/val
    nc: 4
    names: ['anger', 'sad', 'panic', 'happy']
    ```

### [**í›ˆë ¨ ì½”ë“œ**](code/2_YOLO_1_transfer_1.ipynb)
```py
from ultralytics.models import YOLOv10

model_for_trian = YOLOv10("models/yolov10/pt_models/yolov10n.pt")
model_for_trian.train(data="wassup_data.yaml", epochs=10000, imgsz=512, patience=10)
```
- ì†Œìš” ì‹œê°„ : gpu 3060 - 63 epochs completed in 6.935 hours.
- ì—í¬í¬ë³„ val ë©”íŠ¸ë¦­ ë¹„êµ
  ![epoch](models/yolov10/runs/detect/train/val_losses_comparison.png)

  1. **val/box_om** ê°ì²´ì˜ ìœ„ì¹˜ ì˜ˆì¸¡(ë°”ìš´ë”© ë°•ìŠ¤)ì˜ ì†ì‹¤ì„
      - ì´ˆê¸° ì†ì‹¤ì´ ë¹„êµì  ë†’ë‹¤ê°€ epochê°€ ì§„í–‰ë ìˆ˜ë¡ ê¾¸ì¤€íˆ ê°ì†Œ. ì´ëŠ” ëª¨ë¸ì´ í•™ìŠµí•˜ë©´ì„œ ì ì°¨ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ë” ì •í™•íˆ ì˜ˆì¸¡í•˜ê³  ìˆìŒ
  2. **val/cls_om (ìœ„ ì¤‘ê°„)** í´ë˜ìŠ¤ ë¶„ë¥˜ì— ëŒ€í•œ ì†ì‹¤
      - ì²˜ìŒì—ëŠ” ì†ì‹¤ì´ ë†’ì§€ë§Œ epochê°€ ì§„í–‰ë¨ì— ë”°ë¼ ê¸‰ê²©íˆ ê°ì†Œí•˜ê³  ì´í›„ ì ì§„ì ìœ¼ë¡œ ì•ˆì •í™”. ëª¨ë¸ì´ ê°ì²´ë¥¼ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜í•˜ëŠ” ëŠ¥ë ¥ì´ ê°œì„ .
  3. **val/dfl_om (ìœ„ ì˜¤ë¥¸ìª½)** Distribution Focal Loss ì—¬ëŸ¬ í´ë˜ìŠ¤ ê°„ì˜ ë¶„í¬ë¥¼ ê³ ë ¤í•˜ì—¬ ì†ì‹¤ì„ ê³„ì‚°
      - epochê°€ ì§„í–‰ë¨ì— ë”°ë¼ ì•½ê°„ ìƒìŠ¹í•˜ëŠ” íŒ¨í„´ì„ í•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë‹¤ë¥¸ ì†ì‹¤ë“¤ì´ ê°ì†Œí•˜ê³  ìˆê¸° ë•Œë¬¸ì— í° ë¬¸ì œ ì•„ë‹ˆë¼ íŒë‹¨.
  4. **val/box_oo (ì•„ë˜ ì™¼ìª½)**
      - ëª¨ë¸ì´ ì ì°¨ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ë” ì •í™•í•˜ê²Œ ì˜ˆì¸¡.
  5. **val/cls_oo (ì•„ë˜ ì¤‘ê°„)**
      - ëª¨ë¸ì˜ ë¶„ë¥˜ ì„±ëŠ¥ì´ ê°œì„ ë˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
  6. **val/dfl_oo (ì•„ë˜ ì˜¤ë¥¸ìª½)**
      - DFL ì†ì‹¤ì˜ ë˜ ë‹¤ë¥¸ ê·¸ë˜í”„ì…ë‹ˆë‹¤.
      - ì´ ì—­ì‹œ ì´ˆê¸°ì—ëŠ” ì•½ê°„ ë†’ì€ ì†ì‹¤ì„ ë³´ì´ì§€ë§Œ ì´í›„ ê°ì†Œí•˜ê³  ì•ˆì •í™”.
- ìš”ì•½
    - ëŒ€ë¶€ë¶„ì˜ ì†ì‹¤ ê°’ë“¤ì€ epochê°€ ì§„í–‰ë¨ì— ë”°ë¼ ì•ˆì •ì ìœ¼ë¡œ ê°ì†Œ, íŠ¹íˆ **val/box_om**, **val/cls_om**, **val/box_oo**, **val/   cls_oo** ê°™ì€ ì£¼ìš” ì†ì‹¤ í•­ëª©ë“¤ì´ í•™ìŠµì´ ì§„í–‰ë ìˆ˜ë¡ ì¤„ì–´ë“¤ê³  ìˆì–´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ê°œì„ ë˜ê³  ìˆìŒ
    - ë‹¤ë§Œ **val/dfl_om**ì€ epochê°€ ì§„í–‰ë ìˆ˜ë¡ ì•½ê°„ì˜ ì¦ê°€ë¥¼ ë³´ì´ì§€ë§Œ, ì „ì²´ì ì¸ íŠ¸ë Œë“œë¥¼ í¬ê²Œ í•´ì¹˜ì§€ ì•Šìœ¼ë©° ë‹¤ë¥¸ ì†ì‹¤ë“¤ì´ ê¾¸ì¤€íˆ    ì¤„ì–´ë“¤ê³  ìˆìœ¼ë¯€ë¡œ ëª¨ë¸ ì„±ëŠ¥ì—ëŠ” í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šì„ ê±°ë¼ê³  ì˜ˆìƒ. 
    - ì´ ê²°ê³¼ë¡œ ë³¼ ë•Œ, í•™ìŠµ ê³¼ì •ì´ ì˜ ì§„í–‰ë˜ê³  ìˆìœ¼ë©° ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì ì°¨ ì¢‹ì•„ì§€ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ í•´ì„
- ìµœì¢… val/metrics
  - f1 score
    ![epoch](models/yolov10/runs/detect/train/PR_curve.png)
  - PR curve
    ![epoch](models/yolov10/runs/detect/train/F1_curve.png)

## Language Model
### gpt ë˜ëŠ” gemini ë¥¼ ì´ìš©í•œ ë°ì´í„° ì…‹ ìƒì„±
- ì‚¬ìš© ë°ì´í„° ì…‹ : [gpt ìƒì„± ë°ì´í„°](data/text_data/output_text.json)
  - [gpt ìƒì„± ì½”ë“œ](code_data_gen/3_textdata_generating.ipynb)
  - í”„ë¡¬í”„íŒ… : 
    ```py
    def prompting(input_):
    return f"""
    ì‚¬ì§„ì— ëŒ€í•œ ëŒ“ê¸€ ì…ë ¥
    ì§ˆë¬¸ ê¸ˆì§€
    sns ì‚¬ì§„ ìš”ì†Œ : 'ë¶„ë…¸, ì—¬ì, ì¸ê°„ì˜ ì–¼êµ´, ê³µ, ì˜ë¥˜'
    sns ëŒ“ê¸€ : í™”ê°€ ë‚œ ë“¯í•œ í‘œì •ì´ë„¤! ğŸ€ ê³µì€ ë¬´ìŠ¨ ì¢…ë¥˜ì•¼? ì˜·ë„ ë©‹ì§€ë‹¤! ğŸ˜Š
    
    ì˜ˆì¸¡ í•œ ë¬¸ì¥
    sns ì‚¬ì§„ ìš”ì†Œ : {input_}
    sns ëŒ“ê¸€ : """
    ```
  - ì¶œë ¥ ì˜ˆì‹œ :
    ```py
    input_ = 'ê³µí¬, í—¤ë“œí°'
    output_ = 'ì•„ì°”í•œ ë¶„ìœ„ê¸°ë„¤ìš”! ğŸ§ ì–´ë–¤ ìŒì•… ë“£ê³  ê³„ì‹ ê°€ìš”? ê¶ê¸ˆí•´ìš”! ğŸ˜Š'
    ```

### t5 (Text-to-Text Transfer Transformer)

- í•™ìŠµ ë°ì´í„° í˜•ì‹
  ```
  input_data = ['ìŠ¬í””, ë¶„ë…¸', ...]
  output_data = ['ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
  ```

#### ëª¨ë¸ í›ˆë ¨
  - transfer_0 : ê¸°ë³¸ê°’ìœ¼ë¡œ í›ˆë ¨
  - transfer_1 : 
    - ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ 0.1 -> 0.2
    - í›ˆë ¨ì‹œ ì¶”ê°€ ì¸ì
      ```
      learning_rate=5e-5,          # ê¸°ë³¸ê°’ì—ì„œ ì‹œì‘
      lr_scheduler_type="linear",  # ìŠ¤ì¼€ì¤„ëŸ¬
      warmup_steps=500,            # 500 ìŠ¤í… ë™ì•ˆ í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€
      weight_decay=0.01,           # l2 ì •ê·œí™” ê¸°ë²• ì¤‘ í•˜ë‚˜
      max_grad_norm=1.0,           # ê·¸ë¼ë””ì–¸íŠ¸ í´ë¦¬í•‘
      ```
    - transfer_1 : ë¡œì»¬ í™˜ê²½ ë° ê¸°ë³¸ base ëª¨ë¸ ì´ìš©
    - transfer_1_large_colab : colab í™˜ê²½ ë° large ëª¨ë¸ì´ìš©

  - t5 ë¹„êµ ê·¸ë˜í”„
    ![ë¹„êµ ê·¸ë˜í”„](models/t5/val_loss_comparison.png)
  
  - ê²°ë¡  : ì„¸ ëª¨ë¸ì˜ í° ì°¨ì´ëŠ” ì—†ì–´ ë³´ì¸ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì´ì¤‘ íš¨ìœ¨ì¢‹ê³  loss ìµœì €ê°’ì´ ë‚®ì€ 0ë²ˆ(default) ë¡œ ì„ íƒ 
    - ê° ëª¨ë¸ë³„ íŠ¹ì§•
    ```text
    # loss ìµœì €
    - default = 0.1783
    - setting 1 = 0.1790
    - setting 1 with colab = 0.1745

    # ìš”êµ¬ vram
    - default = 6gb
    - setting 1 = 6gb
    - setting 1 with colab = 29gb
    ```




### gpt2 (*Language Models are* **Unsupervised** *Multitask Learners*)
- ì¦‰ ì •ë‹µ ë¼ë²¨ì€ ì—†ë‹¤. (ë¹„ì§€ë„ í•™ìŠµ)
  - í•™ìŠµ ë°ì´í„° í˜•ì‹
    - ì²« ë²ˆì§¸ ë°©ì‹
      ```
      input_data = ['ìŠ¬í””, ë¶„ë…¸, ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
      ```
    - ë‘ ë²ˆì§¸ ë°©ì‹

      ë˜ëŠ” í…ìŠ¤íŠ¸ ë¡œ ì‹œí€€ìŠ¤ ë°ì´í„° ì•ˆì— ëª…ì‹œí•œë‹¤.
      ```
      input_data = ['ì…ë ¥ : ìŠ¬í””, ë¶„ë…¸ \n ì¶œë ¥ : ê°ì •ì´ ë³µì¡í•´ ë³´ì´ë„¤ìš”â€¦ í˜ë“  ë‚ ì´ì‹ ê°€ìš”? â¤ï¸', ... ]
      ```
      ë˜í•œ ì˜ˆì¸¡ì‹œ ëª¨ë¸ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ```'ì…ë ¥ : ìŠ¬í””, ë¶„ë…¸ \n ì¶œë ¥ : ``` ì™€ ê°™ì´ ì…ë ¥í•˜ì—¬ ì¶œë ¥ê°’ì„ ì–»ì–´ì•¼í•¨

- skt ì˜ kogpt2 ì´ìš© : https://huggingface.co/skt/kogpt2-base-v2
  - ì‹œë„ 0
    ```py
    ë°°ì¹˜ : 16
    vram ìš”êµ¬ : ì•½ 6gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ì²« ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° : ê¸°ë³¸ ê°’
    ```
  - ì‹œë„ 1
    ```py
    ë°°ì¹˜ : 16
    vram ìš”êµ¬ : ì•½ 6gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ì²« ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
        learning_rate=5e-5,
        lr_scheduler_type="linear",
        warmup_steps=500,
        weight_decay=0.01[
        max_grad_norm=1.0,
    ```
  - ì‹œë„ 2
    ```py
    ë°°ì¹˜ : 16
    vram ìš”êµ¬ : ì•½ 6gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
      learning_rate=5e-5,
      lr_scheduler_type="linear",
      warmup_steps=500,
      weight_decay=0.01,
      max_grad_norm=1.0,
    ```


- open ai ì˜ gpt2-base ì´ìš© : https://huggingface.co/openai-community/gpt2
  - ì‹œë„ 0
    ```py
    ë°°ì¹˜ : 10
    vram ìš”êµ¬ : ì•½ 5gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° : ê¸°ë³¸ ê°’
    ```
  - ì‹œë„ 1
    ```py
    ë°°ì¹˜ : 10
    vram ìš”êµ¬ : ì•½ 5gb
    ì…ë ¥ ë°ì´í„° í˜•ì‹ : ë‘ ë²ˆì§¸ ë°©ì‹ì˜ í•™ìŠµ ë°ì´í„°
    í•˜ì´í¼ íŒŒë¼ë¯¸í„° :
        learning_rate=5e-5,
        lr_scheduler_type="linear",
        warmup_steps=500,
        weight_decay=0.01,
        max_grad_norm=1.0,
    ```
- ë¹„êµ ê·¸ë˜í”„
  ![ë¹„êµ ê·¸ë˜í”„](models/gpt2//val_loss_comparison.png)

- ê° ëª¨ë¸ ìµœì € loss ë° ìŠ¤í…
  - kogpt2_0 loss : 0.293683
  - kogpt2_1 loss : 0.293336
  - kogpt2_2 loss : 0.72245
  - gpt2_base_0 loss : 0.716322
  - gpt2_base_1 loss : 0.925404

### ê²°ë¡  GPT2 VS T5

- í˜„ í”„ë¡œì íŠ¸ì—ì„œ gpt2 ê³„ì—´ ëª¨ë¸ì¤‘ kogpt ë³´ë‹¤ gpt2 ê¸°ë³¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì˜ ê²°ê³¼ê°€ ë” ì¢‹ì•˜ë‹¤
- ë˜í•œ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì€ T5 ì˜€ë‹¤.

## ëª¨ë¸ ì—°ê²° íŒŒì´í”„ ë¼ì¸

### ğŸ¿[í”„ë¡ íŠ¸ ì—”ë“œ í”„ë¡œì íŠ¸ ë§í¬](https://github.com/crazy2894/project_3_service)ğŸ¿

ì½”ë“œ : [99_pipe_line.ipynb](code/99_pipe_line.ipynb)
ê° ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ë‚˜ì˜¨ ê²°ê³¼

<details>
  <summary>ì½”ë“œ ë³´ê¸°</summary>

```py
import torch
import numpy as np
import cv2
import io
import json
from PIL import Image

from ultralytics import YOLO
from ultralytics.models import YOLOv10
from transformers import T5TokenizerFast, T5ForConditionalGeneration, GPT2Tokenizer, GPT2LMHeadModel


test_image = cv2.imread('test.png')

# ì´ë¯¸ì§€ ëª¨ë¸
model_object_detect = YOLO('models/yolov8x-oiv7.pt')
model_face_emmotion = YOLOv10('models/yolov10n-face.pt')

# í…ìŠ¤íŠ¸ ëª¨ë¸
model_path_gpt2 = 'models/gpt2/models/'
model_gpt2 = GPT2LMHeadModel.from_pretrained(model_path_gpt2)
tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(model_path_gpt2 + '/tokenizer')

model_save_path_t5 = 'models/t5/model/'
model_t5 = T5ForConditionalGeneration.from_pretrained(model_save_path_t5)
tokenizer_t5 = T5TokenizerFast.from_pretrained(model_save_path_t5+ 'tokenizer')

# face ëª¨ë¸ ë¼ë²¨
emotion_mapping = {0 : 'ë¶„ë…¸', 1 : 'ìŠ¬í””', 2 : 'ê³µí¬', 3 : 'ê¸°ì¨'}

# oiv7 ëª¨ë¸ ë¼ë²¨ JSON íŒŒì¼ì—ì„œ ë”•ì…”ë„ˆë¦¬ ì½ê¸°
with open('models/oiv7_jabels.json', 'r') as file:
    oiv7_jabels = json.load(file)

def generate_text_gpt2(prompt, model, tokenizer, max_length=128, num_return_sequences=1):
    # ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”
    inputs = tokenizer.encode(prompt, return_tensors='pt')

    # ìƒì„± ì¸ìë¥¼ ì„¤ì •í•˜ì—¬ ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±
    outputs = model.generate(
        inputs,
        max_length=max_length,
        num_return_sequences=num_return_sequences,
        no_repeat_ngram_size=30,
        top_k=50,
        top_p=0.85,
        temperature=1.7,
        do_sample=True,
        early_stopping=True
    )

    # ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ ë””ì½”ë”©
    generated_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]
    
    return generated_texts

def detect_objects(image: Image.Image):
    # PIL.Imageë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    np_image = np.array(image)
# --------------------------------- ì´ë¯¸ì§€ ì²˜ë¦¬ -------------------------------------------------------------
    # ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì§€
    results_object = model_object_detect(np_image)
    results_face_emotion = model_face_emmotion(np_image)

    # ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    od_image = results_object[0]
    fc_image = results_face_emotion[0]

    # numpy ë°°ì—´ì„ PIL.Imageë¡œ ë³€í™˜
    od_image_pil = Image.fromarray(od_image.plot())
    fc_image_pil = Image.fromarray(fc_image.plot())

    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ í˜•íƒœë¡œ ë³€í™˜
    output1 = io.BytesIO()
    output2 = io.BytesIO()

    od_image_pil.save(output1, format="PNG")
    fc_image_pil.save(output2, format="PNG")

# --------------------------------- í…ìŠ¤íŠ¸ ì²˜ë¦¬ -------------------------------------------------------------
    print(fc_image.boxes.cls)
    print(od_image.boxes.cls)

    label_fc = [oiv7_jabels[str(int(i))] for i in od_image .boxes.cls]
    label_od = [emotion_mapping[int(i)] for i in fc_image.boxes.cls]
    all_labels = label_fc + label_od
    exception_lst = ['ì¸ê°„ì˜ ì–¼êµ´','ì˜ë¥˜','ë‚¨ì','ì—¬ì','ì†Œë…„','ì†Œë…€'] # í…ìŠ¤íŠ¸ ì…ë ¥ ì œì™¸ ëª©ë¡

    text_intput_text = ''
    for i in all_labels:
        if i not in exception_lst:
            text_intput_text +=i + ','

    text_intput_text = text_intput_text[:-1]

    # t5
    # ì…ë ¥ í† í°í™”
    input_ids = tokenizer_t5.encode(text_intput_text, return_tensors='pt')

    # ëª¨ë¸ ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model_t5.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)

    # ì˜ˆì¸¡ ê²°ê³¼ ë””ì½”ë”©
    predicted_text = tokenizer_t5.decode(outputs[0], skip_special_tokens=True)

    t5_out = predicted_text

    # gpt2
    model_gpt2.eval()
    prompt = f"ì…ë ¥ê°’ : {text_intput_text} \nì¶œë ¥ê°’ :"
    generated_texts = generate_text_gpt2(prompt, model_gpt2, tokenizer_gpt2)

    return output1.getvalue(), output2.getvalue() ,t5_out, generated_texts

# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # PIL.Imageë¡œ ë³€í™˜
    image = Image.fromarray(test_image)

    # ê°ì§€ í•¨ìˆ˜ í˜¸ì¶œ
    output1, output2 = detect_objects(image)

    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (í…ŒìŠ¤íŠ¸ìš©)
    with open('test/od_output.png', 'wb') as f:
        f.write(output1)
    
    with open('test/fc_output.png', 'wb') as f:
        f.write(output2)
```

</details>

#### íŒŒì´í”„ ë¼ì¸ í…ŒìŠ¤íŠ¸
<div style="display: flex; justify-content: space-between;">
    <img src="test.png" alt="PR Curve 1" style="width: 45%; height: auto;">
</div>

##### yolov10n-face + yolov8x-oiv7 + t5
ì…ë ¥ê°’: ê³µí¬,ëª¨ì | ì¶œë ¥ê°’: ë¬´ì„œìš´ ë¶„ìœ„ê¸°ê°€ ëŠê»´ì§€ë„¤ìš”! ğŸ˜± ì–´ë–¤ ìƒí™©ì¸ì§€ ê¶ê¸ˆí•´ìš”!

##### yolov10n-face + yolov8x-oiv7 + gpt2
ì…ë ¥ê°’: ê³µí¬,ëª¨ì | ì¶œë ¥ê°’ : ëª¨ì ì•ˆì—ì„œ ëŠê»´ì§€ëŠ” ê³µí¬ê°ì´ ëŠê»´ì§€ë„¤ìš”! ğŸ˜± ë¶„ìœ„ê¸°ê°€ ì •ë§ ê°•ë ¬í•´ìš”! ğŸ–¤ ï¿½

---
<details>
  <summary>íŒŒì¼ êµ¬ì¡°</summary>
  
  ### 2024-09-02
    code\1_ë°ì´í„°_í™•ì¸.ipynb  : fix
    requiremets.txt         : í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¡œ ìˆ˜ì •(ì—…ë°ì´íŠ¸ ì¤‘)
  ## íŒŒì¼ êµ¬ì¡°

  ### ğŸ“ code : ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡, ë°ì´í„° í™•ì¸ê´€ë ¨ ì½”ë“œ
  ```text
  1_ë°ì´í„° í™•ì¸.ipynb           # ë°ì´í„° í™•ì¸ ì½”ë“œ
  2_od_YOLO_finetunning.ipynb  # wassup ì–¼êµ´ ë°ì´í„° ì „ì´í•™ìŠµ
  2_od_YOLO_lvis.ipynb         # lvis ë°ì´í„°ì…‹ ì „ì´í•™ìŠµ
  3_lm_gpt2finetunning         # gpt2 ì „ì´í•™ìŠµ
  3_lm_t5                      # t5 ì „ì´í•™ìŠµ
  4_pipe_line                  # ì…ë ¥ë‹¨ë¶€í„° ìµœì¢… ì¶œë ¥ë‹¨ ê¹Œì§€ìœ¼ íŒŒì´í”„ë¼ì¸
  ```
  
  ### ëª¨ë¸ ì„¤ëª…
  ```text
  yolov8m-oiv7.pt              # ê°ì²´ ê²€ì¶œ ëª¨ë¸ ì¤‘ê°„ ì‚¬ì´ì¦ˆ
  yolov8x-oiv7.pt              # ê°ì²´ ê²€ì¶œ ëª¨ë¸ ë¼ì§€ ì‚¬ì´ì¦ˆ
  yolov10n-face.pt             # wassup datasetìœ¼ë¡œ ì „ì´í•™ìŠµí•œ ëª¨ë¸
  ```
  
  ### ğŸ“ code_data_gen : api ë¥¼ ì´ìš©í•œ ì½”ë“œ
  ```text
  1_chat_gpt_translate.ipynb   # í…ìŠ¤íŠ¸ ë²ˆì—­ ëª¨ë¸ (oiv7 ì˜ ì •ë‹µ ë¼ë²¨ ë²ˆì—­ì„ ìœ„í•œ ì½”ë“œ)
  2_img_pred_and_gen.ipynb     # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í›„ ì¶œë ¥ ê°’ì„ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ì½”ë“œ
  3_textdata_generating.ipynb  # text to text ë¡œ ëŒ“ê¸€ ë°ì´í„° ìƒì„± ì½”ë“œ
  ```
</details>

# ë§í¬ : [ì§„í–‰ê³¼ì • í‘œ](https://docs.google.com/spreadsheets/d/1OklwBcfJiqlj7JJHE1Pez9jpgLctun0BPKrBD4HW2A0/edit?gid=1967477975#gid=1967477975) , [ê¸°íšì•ˆ](https://docs.google.com/presentation/d/1HKMJk6zLfsEqedcVdcQipHY8V8snd6oP2ajS9FDFgKI/edit#slide=id.p), 